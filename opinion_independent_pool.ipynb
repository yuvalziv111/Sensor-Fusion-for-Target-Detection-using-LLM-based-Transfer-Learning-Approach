{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11689548,
          "sourceType": "datasetVersion",
          "datasetId": 7336208
        }
      ],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8MX-dYm-Cj49",
        "outputId": "13a9cd65-7ecd-42b5-b56c-b5c4c4d9310b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, ViTFeatureExtractor, ViTForImageClassification\n",
        "from transformers import AutoModelForTokenClassification\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "from shutil import copyfile\n",
        "from typing import List, Dict, Union, Callable, Optional\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "import matplotlib as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "import pdb\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-07T09:06:20.330256Z",
          "iopub.execute_input": "2025-05-07T09:06:20.331174Z",
          "iopub.status.idle": "2025-05-07T09:06:20.338596Z",
          "shell.execute_reply.started": "2025-05-07T09:06:20.331148Z",
          "shell.execute_reply": "2025-05-07T09:06:20.337552Z"
        },
        "id": "X7Oee_icCAQ0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/train_required_scenes_unified.pt\"\n",
        "labels_path = \"/content/labels_required_scenes_unified.pt\"\n",
        "\n",
        "train = torch.load(train_path)\n",
        "labels = torch.load(labels_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-07T09:06:20.340268Z",
          "iopub.execute_input": "2025-05-07T09:06:20.340579Z",
          "iopub.status.idle": "2025-05-07T09:06:20.386082Z",
          "shell.execute_reply.started": "2025-05-07T09:06:20.340556Z",
          "shell.execute_reply": "2025-05-07T09:06:20.385206Z"
        },
        "id": "Y2O-rN7YCAQ3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihyb2Y9_pINq",
        "outputId": "adf2ae35-3dc9-4c44-9d43-12b16c2732eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1778, 4, 40, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding A-prior probability given lidar intensity"
      ],
      "metadata": {
        "id": "orgBopl1CAQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_close_intensities(intensity_dict, threshold=1.0):\n",
        "    # Sort the keys for sequential processing\n",
        "    sorted_keys = sorted(intensity_dict.keys())\n",
        "\n",
        "    # Initialize the merged dictionary\n",
        "    merged = {}\n",
        "\n",
        "    # Process the first key\n",
        "    if sorted_keys:\n",
        "        current_key = sorted_keys[0]\n",
        "        current_prob = intensity_dict[current_key]\n",
        "\n",
        "        # Process remaining keys\n",
        "        for key in sorted_keys[1:]:\n",
        "            # If keys are close, merge them\n",
        "            if key - current_key < threshold:\n",
        "                # Update probability (sum them)\n",
        "                current_prob += intensity_dict[key]\n",
        "            else:\n",
        "                # Store the accumulated value and move to next group\n",
        "                merged[current_key] = current_prob\n",
        "                current_key = key\n",
        "                current_prob = intensity_dict[key]\n",
        "\n",
        "        # Don't forget to add the last group\n",
        "        merged[current_key] = current_prob\n",
        "\n",
        "    return merged\n",
        "\n",
        "# Example usage:\n",
        "# merged_dict = merge_close_intensities(intensity_prob_dict, threshold=1.0)\n",
        "\n",
        "def calc_prior_probs(train, labels, pos = True):\n",
        "    obj_cases = []\n",
        "    lidar_tensor = train[:, 0, : :].numpy()\n",
        "    num_objects = labels.size()[1]\n",
        "    for i in range(num_objects):\n",
        "        d ={}\n",
        "        obj_label = labels[:,i,:,:].numpy()\n",
        "        if pos is True:\n",
        "            object_present_mask = (obj_label > 0.5)\n",
        "        else:\n",
        "            object_present_mask = (obj_label < 0.5)\n",
        "        lidar_values_where_object = lidar_tensor[object_present_mask]\n",
        "        lidar_values_where_object = np.round(lidar_values_where_object * 10) / 10\n",
        "        unique_values, counts = np.unique(lidar_values_where_object, return_counts=True)\n",
        "        obj_cases.append([unique_values, counts])\n",
        "        # denumenator = np.sum(counts)\n",
        "        # intensity_count_dict = {intensity: count/denumenator for intensity, count in zip(unique_values, counts)}\n",
        "        # intensity_count_dict = merge_close_intensities(intensity_count_dict)\n",
        "    return obj_cases\n",
        "\n",
        "def discretize_and_calculate_likelihood(pos_cases, neg_cases, resolution=0.5, debug=True):\n",
        "    \"\"\"\n",
        "    Discretize intensity values to the specified resolution, combine positive and negative cases,\n",
        "    and calculate likelihood ratio pos_cases / (pos_cases + neg_cases)\n",
        "\n",
        "    Parameters:\n",
        "    - pos_cases: List of [intensities, counts] for positive cases\n",
        "    - neg_cases: List of [intensities, counts] for negative cases\n",
        "    - resolution: Resolution to discretize the intensity values (default: 0.5)\n",
        "    - debug: Print debug information\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary with structure {intensity: likelihood}\n",
        "    \"\"\"\n",
        "    if debug:\n",
        "        print(f\"Number of positive case objects: {len(pos_cases)}\")\n",
        "        print(f\"Number of negative case objects: {len(neg_cases)}\")\n",
        "\n",
        "        # Check first object of each type\n",
        "        if pos_cases:\n",
        "            print(f\"First positive case shape: Intensities={len(pos_cases[0][0])}, Counts={len(pos_cases[0][1])}\")\n",
        "            if len(pos_cases[0][0]) > 0:\n",
        "                print(f\"Sample intensity range: {min(pos_cases[0][0])} to {max(pos_cases[0][0])}\")\n",
        "\n",
        "        if neg_cases:\n",
        "            print(f\"First negative case shape: Intensities={len(neg_cases[0][0])}, Counts={len(neg_cases[0][1])}\")\n",
        "            if len(neg_cases[0][0]) > 0:\n",
        "                print(f\"Sample intensity range: {min(neg_cases[0][0])} to {max(neg_cases[0][0])}\")\n",
        "\n",
        "    # First get the combined dictionary\n",
        "    combined_dict = {}\n",
        "    pos_total = 0\n",
        "    neg_total = 0\n",
        "\n",
        "    # Process positive cases\n",
        "    for i, obj_case in enumerate(pos_cases):\n",
        "        if len(obj_case) != 2:\n",
        "            if debug:\n",
        "                print(f\"Warning: Skipping positive case {i} with unexpected format: {obj_case}\")\n",
        "            continue\n",
        "\n",
        "        intensities, counts = obj_case\n",
        "\n",
        "        if len(intensities) == 0 or len(counts) == 0:\n",
        "            if debug:\n",
        "                print(f\"Warning: Skipping empty positive case {i}\")\n",
        "            continue\n",
        "\n",
        "        if len(intensities) != len(counts):\n",
        "            if debug:\n",
        "                print(f\"Warning: Mismatch in positive case {i}: {len(intensities)} intensities but {len(counts)} counts\")\n",
        "            continue\n",
        "\n",
        "        for intensity, count in zip(intensities, counts):\n",
        "            try:\n",
        "                # Discretize to the nearest multiple of resolution\n",
        "                discretized = round(intensity / resolution) * resolution\n",
        "\n",
        "                # Initialize if not already in the dictionary\n",
        "                if discretized not in combined_dict:\n",
        "                    combined_dict[discretized] = [0, 0]\n",
        "\n",
        "                # Add the count to the positive case (index 0)\n",
        "                combined_dict[discretized][0] += count\n",
        "                pos_total += count\n",
        "            except Exception as e:\n",
        "                if debug:\n",
        "                    print(f\"Error processing positive intensity {intensity}, count {count}: {e}\")\n",
        "\n",
        "    # Process negative cases\n",
        "    for i, obj_case in enumerate(neg_cases):\n",
        "        if len(obj_case) != 2:\n",
        "            if debug:\n",
        "                print(f\"Warning: Skipping negative case {i} with unexpected format: {obj_case}\")\n",
        "            continue\n",
        "\n",
        "        intensities, counts = obj_case\n",
        "\n",
        "        if len(intensities) == 0 or len(counts) == 0:\n",
        "            if debug:\n",
        "                print(f\"Warning: Skipping empty negative case {i}\")\n",
        "            continue\n",
        "\n",
        "        if len(intensities) != len(counts):\n",
        "            if debug:\n",
        "                print(f\"Warning: Mismatch in negative case {i}: {len(intensities)} intensities but {len(counts)} counts\")\n",
        "            continue\n",
        "\n",
        "        for intensity, count in zip(intensities, counts):\n",
        "            try:\n",
        "                # Discretize to the nearest multiple of resolution\n",
        "                discretized = round(intensity / resolution) * resolution\n",
        "\n",
        "                # Initialize if not already in the dictionary\n",
        "                if discretized not in combined_dict:\n",
        "                    combined_dict[discretized] = [0, 0]\n",
        "\n",
        "                # Add the count to the negative case (index 1)\n",
        "                combined_dict[discretized][1] += count\n",
        "                neg_total += count\n",
        "            except Exception as e:\n",
        "                if debug:\n",
        "                    print(f\"Error processing negative intensity {intensity}, count {count}: {e}\")\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Total positive counts: {pos_total}\")\n",
        "        print(f\"Total negative counts: {neg_total}\")\n",
        "        print(f\"Number of unique discretized intensities: {len(combined_dict)}\")\n",
        "        if combined_dict:\n",
        "            print(f\"Sample of combined dictionary:\")\n",
        "            for i, (k, v) in enumerate(combined_dict.items()):\n",
        "                print(f\"  {k}: {v}\")\n",
        "                if i >= 5:\n",
        "                    print(\"  ...\")\n",
        "                    break\n",
        "\n",
        "    # Calculate the likelihood ratio for each intensity\n",
        "    likelihood_dict = {}\n",
        "    for intensity, counts in combined_dict.items():\n",
        "        pos_count = counts[0]\n",
        "        neg_count = counts[1]\n",
        "        total = pos_count + neg_count\n",
        "\n",
        "        # Calculate the likelihood ratio (avoid division by zero)\n",
        "        if total > 0:\n",
        "            likelihood = pos_count / total\n",
        "            likelihood_dict[intensity] = likelihood\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Number of intensities with likelihood calculated: {len(likelihood_dict)}\")\n",
        "        if likelihood_dict:\n",
        "            print(f\"Sample of likelihood dictionary:\")\n",
        "            for i, (k, v) in enumerate(sorted(likelihood_dict.items())):\n",
        "                print(f\"  {k}: {v:.4f}\")\n",
        "                if i >= 5:\n",
        "                    print(\"  ...\")\n",
        "                    break\n",
        "\n",
        "    return likelihood_dict\n",
        "\n",
        "pos_cases = calc_prior_probs(train, labels)\n",
        "neg_cases = calc_prior_probs(train, labels, pos= False)\n",
        "cases_dict = discretize_and_calculate_likelihood(pos_cases, neg_cases)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-07T09:09:57.109597Z",
          "iopub.execute_input": "2025-05-07T09:09:57.109975Z",
          "iopub.status.idle": "2025-05-07T09:09:57.192193Z",
          "shell.execute_reply.started": "2025-05-07T09:09:57.109951Z",
          "shell.execute_reply": "2025-05-07T09:09:57.191424Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HisFDFrPCAQ5",
        "outputId": "5395693d-af66-421c-d042-5a817d94a8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive case objects: 3\n",
            "Number of negative case objects: 3\n",
            "First positive case shape: Intensities=226, Counts=226\n",
            "Sample intensity range: 0.0 to 100.0\n",
            "First negative case shape: Intensities=206, Counts=206\n",
            "Sample intensity range: 0.0 to 100.0\n",
            "Total positive counts: 29421\n",
            "Total negative counts: 6371379\n",
            "Number of unique discretized intensities: 124\n",
            "Sample of combined dictionary:\n",
            "  0.0: [np.int64(364), np.int64(6313628)]\n",
            "  0.5: [np.int64(203), np.int64(406)]\n",
            "  1.0: [np.int64(1539), np.int64(3078)]\n",
            "  1.5: [np.int64(444), np.int64(888)]\n",
            "  2.0: [np.int64(1531), np.int64(3062)]\n",
            "  2.5: [np.int64(1089), np.int64(2178)]\n",
            "  ...\n",
            "Number of intensities with likelihood calculated: 124\n",
            "Sample of likelihood dictionary:\n",
            "  0.0: 0.0001\n",
            "  0.5: 0.3333\n",
            "  1.0: 0.3333\n",
            "  1.5: 0.3333\n",
            "  2.0: 0.3333\n",
            "  2.5: 0.3333\n",
            "  ...\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_objects = 3\n",
        "x_size = 40\n",
        "y_size = 30"
      ],
      "metadata": {
        "id": "YEtiKAttTLK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: for each lidar_data, round the values in each cell of the tensor, and get the value from cases_dict and assign it rather than the original intensity value\n",
        "\n",
        "def replace_intensity_with_likelihood(tensor_data, cases_dict):\n",
        "  \"\"\"Replaces intensity values in lidar_data with likelihoods from cases_dict.\n",
        "\n",
        "  Args:\n",
        "    lidar_data: A tensor representing lidar data.\n",
        "    cases_dict: A dictionary mapping discretized intensity values to likelihoods.\n",
        "\n",
        "  Returns:\n",
        "    A tensor with intensity values replaced by likelihoods.\n",
        "  \"\"\"\n",
        "  lidar_data = tensor_data[0, :, :]\n",
        "  # Ensure cases_dict is not empty\n",
        "  if not cases_dict:\n",
        "    print(\"Warning: cases_dict is empty. Returning original lidar_data.\")\n",
        "    return lidar_data\n",
        "\n",
        "  # Find the minimum and maximum keys in cases_dict for clamping\n",
        "  min_key = min(cases_dict.keys())\n",
        "  max_key = max(cases_dict.keys())\n",
        "\n",
        "  # Iterate over the lidar data and replace intensity values with likelihoods\n",
        "  new_lidar_data = lidar_data.clone()  # Create a copy to avoid modifying the original tensor\n",
        "  for i in range(lidar_data.shape[0]):\n",
        "    for j in range(lidar_data.shape[1]):\n",
        "      intensity = lidar_data[i, j].item()\n",
        "      discretized_intensity = round(intensity / 0.5) * 0.5 # Use the same discretization as in the likelihood calculation\n",
        "      discretized_intensity = max(min(discretized_intensity, max_key), min_key) # Clamp the discretized intensity\n",
        "      if discretized_intensity in cases_dict:\n",
        "        new_lidar_data[i, j] = cases_dict[discretized_intensity]\n",
        "      else:\n",
        "        # Handle cases where the discretized intensity is not in the dictionary\n",
        "        # You can choose to either use a default value or the original intensity\n",
        "        new_lidar_data[i, j] = 0.0  # or lidar_data[i, j, k]\n",
        "\n",
        "  return new_lidar_data.numpy()\n",
        "\n",
        "def process_tensor(tensor):\n",
        "    \"\"\"\n",
        "    Processes a tensor based on the provided criteria.\n",
        "\n",
        "    Args:\n",
        "      tensor: The input tensor.\n",
        "\n",
        "    Returns:\n",
        "      A list of tensors.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for i in range(1, 4):  # Ignore element 0, process elements 1, 2, 3\n",
        "    #devide by 1000 each element since we multiplied by 100 for enabeling to use Llama model\n",
        "      result.append((tensor[i, :, :].numpy()) / 1000)\n",
        "    return result\n",
        "\n",
        "def opinion_independent_pool_calc(lidar_prob_map, processed_tensor):\n",
        "  probability_maps = []\n",
        "  for obj_map in processed_tensor:\n",
        "    p = np.zeros(lidar_prob_map.shape)\n",
        "    for i in range(lidar_prob_map.shape[0]):\n",
        "      for j in range(lidar_prob_map.shape[1]):\n",
        "        p[i][j] = (lidar_prob_map[i][j] * obj_map[i][j]) / (lidar_prob_map[i][j] * obj_map[i][j] + (1 - lidar_prob_map[i][j]) * (1 - obj_map[i][j]))\n",
        "        if p[i][j] < 0:\n",
        "          display(\"got a negative value!\")\n",
        "          display(\"p_i_j: \", p[i][j])\n",
        "          display(\"lidar: \", lidar_prob_map[i][j])\n",
        "          display(\"optical: \", obj_map[i][j])\n",
        "    probability_maps.append(p)\n",
        "  return probability_maps\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-ggeHnxVDUWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Opinion Independent Pool"
      ],
      "metadata": {
        "id": "sEHz9WL3XEDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage assuming 'train' is your 440x4x40x30 tensor\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "# Define the split ratio (e.g., 80% train, 20% test)\n",
        "train_size = int(0.8 * len(train))\n",
        "test_size = len(train) - train_size\n",
        "\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Random split\n",
        "train_dataset, test_dataset = random_split(train, [train_size, test_size], generator = generator)\n",
        "\n",
        "# Get indices used in the split\n",
        "train_indices = train_dataset.indices\n",
        "test_indices = test_dataset.indices\n",
        "\n",
        "# Split the labels tensor using the same indices\n",
        "train_labels = labels[train_indices]\n",
        "test_labels = labels[test_indices]"
      ],
      "metadata": {
        "id": "BxgldEqryOTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WexYuFNYQ2_S",
        "outputId": "56d1d5d4-3f0a-491a-e88d-a6e6c8220b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 40, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "processed_tensors = []\n",
        "prob_tensor = torch.empty(0,num_objects,x_size,y_size)\n",
        "preds_tensor = torch.empty(0,num_objects,x_size,y_size)\n",
        "for i in tqdm(range(len(test_dataset))):\n",
        "    tensor_to_process = test_dataset[i]\n",
        "    optical_tensors = process_tensor(tensor_to_process)\n",
        "    lidar_prob_map = replace_intensity_with_likelihood(tensor_to_process, cases_dict)\n",
        "    probability_maps = opinion_independent_pool_calc(lidar_prob_map, optical_tensors)\n",
        "    preds = []\n",
        "    prob_maps = []\n",
        "    for probability_map in probability_maps:\n",
        "      rounded_map = np.where(probability_map > 0.5, 1, 0)\n",
        "\n",
        "      prob_maps.append(probability_map)\n",
        "      preds.append(rounded_map)\n",
        "\n",
        "    preds_tensor = torch.cat((preds_tensor, torch.tensor(preds).unsqueeze(0)), dim=0)\n",
        "    prob_tensor = torch.cat((prob_tensor, torch.tensor(prob_maps).unsqueeze(0)), dim=0)\n",
        "# prompt: convert labels tensor o dtype-double\n",
        "labels = labels.double()\n",
        "prob_tensor = prob_tensor.double()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXabgITnVP04",
        "outputId": "8c97d570-9eb9-45a2-cbe9-16a1c3fa069e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/356 [00:00<?, ?it/s]<ipython-input-10-2210575dd93c>:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  preds_tensor = torch.cat((preds_tensor, torch.tensor(preds).unsqueeze(0)), dim=0)\n",
            "100%|██████████| 356/356 [00:34<00:00, 10.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedBCELoss(nn.BCELoss):\n",
        "    \"\"\"\n",
        "    Weighted Binary Cross Entropy Loss that applies higher weights to positive examples.\n",
        "    Inherits from PyTorch's BCELoss for compatibility.\n",
        "\n",
        "    Args:\n",
        "        pos_weight: Weight multiplier for positive examples (default: 10.0)\n",
        "        reduction: Specifies the reduction to apply to the output ('none', 'mean', 'sum')\n",
        "        weight: A manual rescaling weight given to the loss of each batch element\n",
        "    \"\"\"\n",
        "    def __init__(self, pos_weight=10.0, weight=None, size_average=None, reduce=None, reduction='mean'):\n",
        "        super(WeightedBCELoss, self).__init__(weight, size_average, reduce, reduction)\n",
        "        self.pos_weight = pos_weight\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        \"\"\"\n",
        "        Forward pass for weighted BCE loss\n",
        "\n",
        "        Args:\n",
        "            input: Predicted probabilities (B, ...)\n",
        "            target: Ground truth binary values (B, ...)\n",
        "\n",
        "        Returns:\n",
        "            Weighted BCE loss\n",
        "        \"\"\"\n",
        "        # Create weight tensor where positive examples get higher weight\n",
        "        weights = torch.ones_like(target)\n",
        "        weights[target == 1] = self.pos_weight\n",
        "\n",
        "        # Calculate BCE loss element-wise (without reduction)\n",
        "        bce = F.binary_cross_entropy(input, target, reduction='none')\n",
        "\n",
        "        # Apply weights to the loss\n",
        "        weighted_bce = bce * weights\n",
        "\n",
        "        # Apply reduction\n",
        "        if self.reduction == 'mean':\n",
        "            return weighted_bce.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return weighted_bce.sum()\n",
        "        else:  # 'none'\n",
        "            return weighted_bce"
      ],
      "metadata": {
        "id": "H92kKUCPAEoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_tensor = prob_tensor.double()\n",
        "test_labels = test_labels.double()"
      ],
      "metadata": {
        "id": "G4FjcdI1APkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: calculate the loss between prob_tensor and label_batch. use BCELoss\n",
        "pos_weight = torch.tensor([10.0])\n",
        "criterion = WeightedBCELoss(pos_weight=pos_weight)\n",
        "loss = criterion(prob_tensor, test_labels)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3vhaxq0Ertu",
        "outputId": "8538e4bb-2b45-4fd0-9532-e23a452ba9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.2891, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: calculate accuracy score, precision, recall and f1 score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Flatten the predictions and labels for easier calculations\n",
        "preds_flat = preds_tensor.flatten().numpy()\n",
        "labels_flat = test_labels.flatten().numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(labels_flat, preds_flat)\n",
        "precision = precision_score(labels_flat, preds_flat)\n",
        "recall = recall_score(labels_flat, preds_flat)\n",
        "f1 = f1_score(labels_flat, preds_flat)\n",
        "auc = roc_auc_score(labels_flat, preds_flat)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"AUC Score: {auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9LvWDOtbkcp",
        "outputId": "ef08d34c-0220-4377-a575-8e57a3665643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9953206928838951\n",
            "Precision: 0.36743515850144093\n",
            "Recall: 0.04386719421985206\n",
            "F1 Score: 0.07837713231904103\n",
            "AUC Score: 0.5217615464462965\n"
          ]
        }
      ]
    }
  ]
}