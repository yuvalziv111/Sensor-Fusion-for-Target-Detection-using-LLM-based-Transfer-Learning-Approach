{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "UKy52tbSKKcz"
      },
      "source": [
        "%pip install optuna\n",
        "%pip install grpcio==1.70.0\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R8WaHI6-OctV",
        "outputId": "003645ec-3f09-470f-ceef-79654abede51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Collecting grpcio==1.70.0\n",
            "  Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: grpcio\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.72.1\n",
            "    Uninstalling grpcio-1.72.1:\n",
            "      Successfully uninstalled grpcio-1.72.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires grpcio>=1.71.0, but you have grpcio 1.70.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.70.0\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install optuna\n",
        "%pip install grpcio==1.70.0\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBPgdC1zKKc3"
      },
      "outputs": [],
      "source": [
        "#For running the notebook, please first define processing = True for the first part and after that use processing = False without restarting to run the Llama model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsTCvlwRKKc5"
      },
      "outputs": [],
      "source": [
        "# %pip install datasets\n",
        "# %pip install optuna\n",
        "# %pip install grpcio==1.70.0\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, ViTFeatureExtractor, ViTForImageClassification\n",
        "from transformers import AutoModelForTokenClassification\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "from shutil import copyfile\n",
        "from typing import List, Dict, Union, Callable, Optional\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "import matplotlib as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "import pdb\n",
        "from torch.nn import BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK0EW7hcOSeD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iILxOL6KKc6"
      },
      "outputs": [],
      "source": [
        "num_objects = 3\n",
        "x_size = 40\n",
        "y_size = 30\n",
        "processing = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuJtgEmWKKc6"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXR1yCOVKKc8"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2DuZCsJKKc9"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "if processing is True:\n",
        "    class myDataset(Dataset):\n",
        "        \"\"\"\n",
        "        Dataset class for NuScenes tensor files.\n",
        "\n",
        "        Args:\n",
        "            training_data: Tensor of shape [num_samples, channels, height, width]\n",
        "            labels_data: Tensor of labels corresponding to training data\n",
        "        \"\"\"\n",
        "        def __init__(self, training_data, labels_data):\n",
        "            self.training_data = training_data\n",
        "            self.labels_data = labels_data\n",
        "\n",
        "            # Verify shapes match\n",
        "            assert len(training_data) == len(labels_data), \"Training data and labels must have same number of samples\"\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.training_data)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return self.training_data[idx], self.labels_data[idx]\n",
        "\n",
        "    files_path = \"/content/nuscenes-tensor-files/\"\n",
        "\n",
        "    train_path = fr'/content/training_batch_3_meter_grid.pt'\n",
        "    labels_path = fr'/content/label_batch_3_meter_grid.pt'\n",
        "\n",
        "    train = torch.load(train_path, map_location=torch.device('cpu'))\n",
        "    labels = torch.load(labels_path, map_location=torch.device('cpu'))\n",
        "        # Define the neural network architecture\n",
        "    def calc_prior_probs(train, labels, pos = True):\n",
        "        obj_cases = []\n",
        "        lidar_tensor = train[:, 0, : :].numpy()\n",
        "        num_objects = labels.size()[1]\n",
        "        for i in range(num_objects):\n",
        "            d ={}\n",
        "            obj_label = labels[:,i,:,:].numpy()\n",
        "            if pos is True:\n",
        "                object_present_mask = (obj_label > 0.5)\n",
        "            else:\n",
        "                object_present_mask = (obj_label < 0.5)\n",
        "            lidar_values_where_object = lidar_tensor[object_present_mask]\n",
        "            lidar_values_where_object = np.round(lidar_values_where_object * 10) / 10\n",
        "            unique_values, counts = np.unique(lidar_values_where_object, return_counts=True)\n",
        "            obj_cases.append([unique_values, counts])\n",
        "            # denumenator = np.sum(counts)\n",
        "            # intensity_count_dict = {intensity: count/denumenator for intensity, count in zip(unique_values, counts)}\n",
        "            # intensity_count_dict = merge_close_intensities(intensity_count_dict)\n",
        "        return obj_cases\n",
        "\n",
        "\n",
        "\n",
        "    class SimpleClassifier(nn.Module):\n",
        "        def __init__(self, input_size, hidden_size, output_size):\n",
        "            super(SimpleClassifier, self).__init__()\n",
        "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "            # Changed floating-point division to integer division\n",
        "            self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "            self.relu = nn.ReLU()\n",
        "            # Changed floating-point division to integer division\n",
        "            self.sigmoid = nn.Sigmoid()\n",
        "        def forward(self, x):\n",
        "            x = x.view(x.size(0), -1)  # Flatten the input\n",
        "            x = self.fc1(x)\n",
        "            x = self.relu(x)\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "    prob_lidar_model =SimpleClassifier(input_size=x_size * y_size, hidden_size = x_size * y_size * 64, output_size = x_size * y_size)\n",
        "    state_dict = torch.load('/content/simple_classifier_state_dict.pth', map_location = torch.device('cpu'))\n",
        "    prob_lidar_model.load_state_dict(state_dict)\n",
        "    prob_lidar_model.eval()  # Set to evaluation mode\n",
        "    def predict_lidar_ptobability(tensor_data):\n",
        "        \"\"\"Replaces intensity values in lidar_data with likelihoods from cases_dict.\n",
        "\n",
        "        Args:\n",
        "        lidar_data: A tensor representing lidar data.\n",
        "        cases_dict: A dictionary mapping discretized intensity values to likelihoods.\n",
        "\n",
        "        Returns:\n",
        "        A tensor with intensity values replaced by likelihoods.\n",
        "        \"\"\"\n",
        "        lidar_data = tensor_data[0, :, :]\n",
        "\n",
        "\n",
        "\n",
        "        new_lidar_data = lidar_data.clone()  # Create a copy to avoid modifying the original tensor\n",
        "        lidar_data_prob = prob_lidar_model(new_lidar_data)\n",
        "        lidar_data_prob = lidar_data_prob * 1000\n",
        "\n",
        "        return lidar_data_prob.unsqueeze(0)\n",
        "\n",
        "    def process_tensor(tensor):\n",
        "        \"\"\"\n",
        "        Processes a tensor based on the provided criteria.\n",
        "\n",
        "        Args:\n",
        "          tensor: The input tensor.\n",
        "\n",
        "        Returns:\n",
        "          A list of tensors.\n",
        "        \"\"\"\n",
        "        optical_tensor = tensor[1:4, :, :]\n",
        "        return optical_tensor\n",
        "\n",
        "    processed_train = torch.empty(0,num_objects + 1,x_size,y_size)\n",
        "    for i in tqdm(range(train.size()[0])):\n",
        "        tensor_to_process = train[i]\n",
        "        optical_tensors = process_tensor(tensor_to_process)\n",
        "        lidar_prob_map = predict_lidar_ptobability(tensor_to_process)\n",
        "        concat_lidar_opt = torch.cat([lidar_prob_map, optical_tensors], dim=0)\n",
        "        processed_train = torch.cat((processed_train, concat_lidar_opt.unsqueeze(0)), dim=0)\n",
        "    training_set = myDataset(processed_train, labels)\n",
        "\n",
        "    total_size = len(processed_train)\n",
        "    train_size = int(0.85 * total_size)  # Using 80% for training\n",
        "    test_size = total_size - train_size   # Using 20% for validation\n",
        "\n",
        "    generator = torch.Generator().manual_seed(42)\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    train_dataset, test_dataset = random_split(training_set, [train_size, test_size], generator = generator)\n",
        "    torch.save(train_dataset, \"/content/train_dataset.pt\")\n",
        "    torch.save(test_dataset, \"/content/test_dataset.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTGVkeldKKc-"
      },
      "outputs": [],
      "source": [
        "# train_dataset = torch.load(\"/content/test_dataset.pt\")\n",
        "# test_dataset = torch.load(\"/content/test_dataset.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVPMs8f8KQWq"
      },
      "outputs": [],
      "source": [
        "# prompt: rather than loading llama please load GPT-2\n",
        "# torch.cuda.empty_cache()\n",
        "# # Load model directly\n",
        "# from huggingface_hub import login\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "# login(\"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\")\n",
        "# gpt2_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
        "# gpt2_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "# Load model directly\n",
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "login(\"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\")\n",
        "gpt2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "gpt2_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oY95TKVS4v7"
      },
      "outputs": [],
      "source": [
        "type(gpt2_tokenizer.encode(\"Hello, my dog is cute so much\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcdraJZnQ_xe"
      },
      "outputs": [],
      "source": [
        "class GPT2Model(nn.Module):\n",
        "  def __init__(self, input_shape=[num_objects+1, x_size, y_size], gpt2_model=gpt2_model):\n",
        "      super(GPT2Model, self).__init__()\n",
        "      self.gpt2_model = gpt2_model\n",
        "      self.input_shape = input_shape\n",
        "\n",
        "      # Calculate the flattened size of a single grid map\n",
        "      single_map_size = input_shape[1] * input_shape[2]\n",
        "\n",
        "      # The GPT2 model will output a hidden state for each input token (map embedding).\n",
        "      # The default output size of GPT-2's transformer layer is `config.hidden_size`.\n",
        "      # We need to match the output layer's input size to the GPT-2's output size\n",
        "      # multiplied by the number of input maps (sequence length).\n",
        "\n",
        "      gpt2_hidden_size = self.gpt2_model.config.hidden_size\n",
        "      num_input_maps = input_shape[0]\n",
        "\n",
        "      # The output of the GPT2 model for inputs_embeds will be of shape\n",
        "      # (batch_size, num_input_maps, gpt2_hidden_size).\n",
        "      # Our desired output shape is (batch_size, num_output_maps, x_size, y_size).\n",
        "      # We need a linear layer to transform the GPT2 output to the desired shape.\n",
        "      num_output_maps = num_input_maps - 1\n",
        "      total_output_size = num_output_maps * input_shape[1] * input_shape[2]\n",
        "\n",
        "      # The input size to the output layer should be the flattened output of GPT-2 hidden states\n",
        "      # This was the source of the error.\n",
        "      gpt2_flattened_output_size = num_input_maps * gpt2_hidden_size\n",
        "\n",
        "      self.output_layer = nn.Linear(gpt2_flattened_output_size, total_output_size)\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "      # Projection layer to convert grid maps to GPT2 embedding size\n",
        "      self.projection_layer = nn.Linear(input_shape[1] * input_shape[2], gpt2_hidden_size)\n",
        "\n",
        "      # Freeze GPT2 model parameters\n",
        "      for param in self.gpt2_model.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "  def forward(self, grid_maps):\n",
        "        print(f\"Input grid_maps shape: {grid_maps.shape}\")\n",
        "        batch_size = grid_maps.size(0)\n",
        "        num_maps = self.input_shape[0]\n",
        "        num_output_maps = num_maps - 1\n",
        "        # Reshape grid_maps from (batch_size, num_maps, x_size, y_size) to (batch_size, num_maps, x_size * y_size)\n",
        "        reshaped_maps = grid_maps.view(batch_size, num_maps, -1).float()\n",
        "\n",
        "        # Project each map to GPT2 hidden size\n",
        "        # First reshape to (batch_size * num_maps, flattened_size)\n",
        "        projected_maps = self.projection_layer(reshaped_maps.view(-1, self.input_shape[1] * self.input_shape[2]))\n",
        "\n",
        "        # Reshape back to (batch_size, num_maps, gpt2_hidden_size)\n",
        "        projected_maps = projected_maps.view(batch_size, num_maps, self.gpt2_model.config.hidden_size)\n",
        "\n",
        "        # Pass through GPT2 model with output_hidden_states=True to ensure we get hidden states\n",
        "        gpt2_outputs = self.gpt2_model(inputs_embeds=projected_maps, output_hidden_states=True)\n",
        "\n",
        "        # Extract hidden states: for CausalLMOutputWithCrossAttentions, use .hidden_states[-1] or .logits\n",
        "        # The hidden states have shape (batch_size, num_maps, gpt2_hidden_size)\n",
        "        if hasattr(gpt2_outputs, 'last_hidden_state'):\n",
        "            hidden_states = gpt2_outputs.last_hidden_state\n",
        "\n",
        "        elif hasattr(gpt2_outputs, 'hidden_states') and gpt2_outputs.hidden_states:\n",
        "            hidden_states = gpt2_outputs.hidden_states[-1]  # Get the last layer's hidden states\n",
        "\n",
        "        else:\n",
        "            # Fallback: use the raw output (this might need adjustment based on your specific GPT-2 setup)\n",
        "            hidden_states = gpt2_outputs[0] if isinstance(gpt2_outputs, tuple) else gpt2_outputs\n",
        "\n",
        "        # Flatten the hidden states for the output layer\n",
        "        flattened_hidden = hidden_states.view(batch_size, -1)  # (batch_size, num_maps * gpt2_hidden_size)\n",
        "\n",
        "        # Pass through output layer\n",
        "        output = self.output_layer(flattened_hidden)\n",
        "\n",
        "        # Apply sigmoid activation\n",
        "        output = self.sigmoid(output)\n",
        "\n",
        "\n",
        "        # Reshape the output to the desired grid map shape (batch_size, num_output_maps, x_size, y_size)\n",
        "        output = output.view(batch_size, num_output_maps, self.input_shape[1], self.input_shape[2])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp4260rNKKdC"
      },
      "outputs": [],
      "source": [
        "def plot_loss(train_loss, test_loss):\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_loss, 'bo-', label='Train loss')\n",
        "    plt.plot(epochs, test_loss, 'ro-', label='Test loss')\n",
        "    plt.title('Training and Testing Loss over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i01Ht51CKKdD"
      },
      "outputs": [],
      "source": [
        "class WeightedBCELoss(nn.BCELoss):\n",
        "    \"\"\"\n",
        "    Weighted Binary Cross Entropy Loss that applies higher weights to positive examples.\n",
        "    Inherits from PyTorch's BCELoss for compatibility.\n",
        "\n",
        "    Args:\n",
        "        pos_weight: Weight multiplier for positive examples (default: 10.0)\n",
        "        reduction: Specifies the reduction to apply to the output ('none', 'mean', 'sum')\n",
        "        weight: A manual rescaling weight given to the loss of each batch element\n",
        "    \"\"\"\n",
        "    def __init__(self, pos_weight=10.0, weight=None, size_average=None, reduce=None, reduction='mean'):\n",
        "        super(WeightedBCELoss, self).__init__(weight, size_average, reduce, reduction)\n",
        "        self.pos_weight = pos_weight\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        \"\"\"\n",
        "        Forward pass for weighted BCE loss\n",
        "\n",
        "        Args:\n",
        "            input: Predicted probabilities (B, ...)\n",
        "            target: Ground truth binary values (B, ...)\n",
        "\n",
        "        Returns:\n",
        "            Weighted BCE loss\n",
        "        \"\"\"\n",
        "        # Create weight tensor where positive examples get higher weight\n",
        "        weights = torch.ones_like(target)\n",
        "        weights[target == 1] = self.pos_weight\n",
        "\n",
        "        # Calculate BCE loss element-wise (without reduction)\n",
        "        bce = F.binary_cross_entropy(input, target, reduction='none')\n",
        "\n",
        "        # Apply weights to the loss\n",
        "        weighted_bce = bce * weights\n",
        "\n",
        "        # Apply reduction\n",
        "        if self.reduction == 'mean':\n",
        "            return weighted_bce.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return weighted_bce.sum()\n",
        "        else:  # 'none'\n",
        "            return weighted_bce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPZ_Og8CKKdD"
      },
      "outputs": [],
      "source": [
        "def training_loop(model, params, train_df_dataset=train_dataset, test_df_dataset=test_dataset, kf_splits=5):\n",
        "    from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "    num_epochs = params['num_epochs']\n",
        "    batch_size = params['batch_size']\n",
        "    learning_rate = params['learning_rate']\n",
        "    num_layers_to_train = params['num_layers_to_train']\n",
        "\n",
        "    # Get all the layers in the model\n",
        "    layers = list(gpt2_model.transformer.h)\n",
        "    num_layers = len(layers)\n",
        "\n",
        "    # Unfreeze the last 10 layers\n",
        "    for i in range(num_layers - 5, num_layers):\n",
        "        for param in layers[i].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    # You can verify which parameters will be updated\n",
        "    total_params = 0\n",
        "    trainable_params = 0\n",
        "    for name, param in gpt2_model.named_parameters():\n",
        "        total_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    kf = KFold(n_splits=kf_splits, shuffle=True, random_state=42)\n",
        "    pos_weight = torch.tensor([10.0]).to(device)\n",
        "    criterion = WeightedBCELoss(pos_weight=pos_weight)\n",
        "\n",
        "    model.to(device)\n",
        "    avg_val_loss_lst = []\n",
        "    avg_train_loss_lst = []\n",
        "    avg_train_loss_lst_fold, avg_val_loss_lst_fold = [], []\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(kf.split(np.arange(len(train_df_dataset)))):\n",
        "      train_subset = torch.utils.data.Subset(train_df_dataset, train_index)\n",
        "      val_subset = torch.utils.data.Subset(train_df_dataset, test_index)\n",
        "      train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "      val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False) # Important: shuffle=False here.\n",
        "\n",
        "\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "      scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=1e-3,  # Peak learning rate to reach\n",
        "        epochs=20,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        pct_start=0.3,  # Spend 30% of training ramping up\n",
        "        div_factor=25.0,  # Initial LR = max_lr/div_factor\n",
        "        three_phase=False\n",
        "        )\n",
        "\n",
        "      for epoch in tqdm(range(num_epochs)):\n",
        "          train_loss, val_loss = [], []\n",
        "          model.train()\n",
        "          for data, labels in train_loader:\n",
        "             data, labels = data.to(device), labels.to(device)\n",
        "             model_output = model(data)\n",
        "             loss = criterion(model_output, labels)\n",
        "             train_loss.append(loss.item())\n",
        "             optimizer.zero_grad()\n",
        "             loss.backward(retain_graph=True )\n",
        "             optimizer.step()\n",
        "          avg_train_loss_lst_fold.append(sum(train_loss) / len(train_loss))\n",
        "\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "              for data, labels in val_loader:\n",
        "                  data, labels = data.to(device), labels.to(device).float()\n",
        "                  val_output = model(data)\n",
        "                  loss = criterion(val_output, labels)\n",
        "                  val_loss.append(loss.item())\n",
        "                  preds = (val_output >= 0.5).float()\n",
        "\n",
        "          avg_val_loss_lst_fold.append(sum(val_loss) / len(val_loss))\n",
        "      avg_train_loss_lst.append(sum(avg_train_loss_lst_fold) / len(avg_train_loss_lst_fold))\n",
        "      avg_val_loss_lst.append(sum(avg_val_loss_lst_fold) / len(avg_val_loss_lst_fold))\n",
        "\n",
        "    #test set\n",
        "    test_loader = DataLoader(test_df_dataset, batch_size=batch_size, shuffle=True)\n",
        "    true_labels = []\n",
        "    test_preds = []\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for data, labels in test_loader:\n",
        "          data, labels = data.to(device), labels.to(device).float()\n",
        "          test_output = model(data).flatten()\n",
        "          labels = labels.flatten()\n",
        "          preds = (test_output >= 0.5).float()\n",
        "          true_labels.extend(labels.cpu().numpy())\n",
        "          test_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    avg_train_loss_lst_epochs = np.array(avg_train_loss_lst_fold).reshape(kf_splits,num_epochs)\n",
        "    avg_train_loss_lst_epochs = list(np.mean(avg_train_loss_lst_epochs, axis=0))\n",
        "    avg_val_loss_lst_epochs = np.array(avg_val_loss_lst_fold).reshape(kf_splits,num_epochs)\n",
        "    avg_val_loss_lst_epochs = list(np.mean(avg_val_loss_lst_epochs, axis=0))\n",
        "    # Example usage\n",
        "    display(\"Accuracy: \", accuracy_score(true_labels, test_preds))\n",
        "    display(\"Recall Score: \", recall_score(true_labels, test_preds))\n",
        "    display(\"Precision Score: \", precision_score(true_labels, test_preds))\n",
        "    display(\"AUC Score: \", roc_auc_score(true_labels, test_preds))\n",
        "    display(\"Loss: \",sum(avg_val_loss_lst) / len(avg_val_loss_lst))\n",
        "    plot_loss(avg_train_loss_lst_epochs, avg_val_loss_lst_epochs)\n",
        "\n",
        "    test_results = []\n",
        "    for i in range(len(test_loader.dataset)):\n",
        "        item = test_loader.dataset.__getitem__(i)\n",
        "        data = item[0]\n",
        "        label = item[1]\n",
        "        pred = test_preds[i]\n",
        "        test_results.append([data, label, pred])\n",
        "    test_results = pd.DataFrame(test_results, columns=['data', 'label', 'pred'])\n",
        "    return sum(avg_val_loss_lst) / len(avg_val_loss_lst), test_results, model"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "idqPUEuHKKdE"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2sBeKz5tKKdE",
        "outputId": "baa856c2-abef-4d4d-8ea0-908c2c0ab913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-13 09:40:47,538] A new study created in memory with name: no-name-9e57cccc-cc50-408b-b221-f3cca7a2bfb7\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid_maps shape: torch.Size([16, 4, 40, 30])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Reshaped maps shape: torch.Size([16, 4, 1200])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after first reshape) shape: torch.Size([64, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after second reshape) shape: torch.Size([16, 4, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"GPT2 outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Extracted hidden states using 'hidden_states[-1]'. Shape: torch.Size([16, 4, 768])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Flattened hidden states shape: torch.Size([16, 3072])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output before sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output after sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Final output shape after reshaping: torch.Size([16, 3, 40, 30])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid_maps shape: torch.Size([16, 4, 40, 30])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Reshaped maps shape: torch.Size([16, 4, 1200])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after first reshape) shape: torch.Size([64, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after second reshape) shape: torch.Size([16, 4, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"GPT2 outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Extracted hidden states using 'hidden_states[-1]'. Shape: torch.Size([16, 4, 768])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Flattened hidden states shape: torch.Size([16, 3072])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output before sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output after sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Final output shape after reshaping: torch.Size([16, 3, 40, 30])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid_maps shape: torch.Size([16, 4, 40, 30])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Reshaped maps shape: torch.Size([16, 4, 1200])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after first reshape) shape: torch.Size([64, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after second reshape) shape: torch.Size([16, 4, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"GPT2 outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Extracted hidden states using 'hidden_states[-1]'. Shape: torch.Size([16, 4, 768])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Flattened hidden states shape: torch.Size([16, 3072])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output before sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output after sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Final output shape after reshaping: torch.Size([16, 3, 40, 30])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid_maps shape: torch.Size([16, 4, 40, 30])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Reshaped maps shape: torch.Size([16, 4, 1200])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after first reshape) shape: torch.Size([64, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after second reshape) shape: torch.Size([16, 4, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"GPT2 outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Extracted hidden states using 'hidden_states[-1]'. Shape: torch.Size([16, 4, 768])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Flattened hidden states shape: torch.Size([16, 3072])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output before sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output after sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Final output shape after reshaping: torch.Size([16, 3, 40, 30])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid_maps shape: torch.Size([16, 4, 40, 30])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Reshaped maps shape: torch.Size([16, 4, 1200])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after first reshape) shape: torch.Size([64, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after second reshape) shape: torch.Size([16, 4, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"GPT2 outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Extracted hidden states using 'hidden_states[-1]'. Shape: torch.Size([16, 4, 768])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Flattened hidden states shape: torch.Size([16, 3072])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output before sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output after sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Final output shape after reshaping: torch.Size([16, 3, 40, 30])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid_maps shape: torch.Size([16, 4, 40, 30])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Reshaped maps shape: torch.Size([16, 4, 1200])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after first reshape) shape: torch.Size([64, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after second reshape) shape: torch.Size([16, 4, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"GPT2 outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Extracted hidden states using 'hidden_states[-1]'. Shape: torch.Size([16, 4, 768])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Flattened hidden states shape: torch.Size([16, 3072])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output before sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output after sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Final output shape after reshaping: torch.Size([16, 3, 40, 30])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid_maps shape: torch.Size([16, 4, 40, 30])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Reshaped maps shape: torch.Size([16, 4, 1200])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after first reshape) shape: torch.Size([64, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Projected maps (after second reshape) shape: torch.Size([16, 4, 768])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"GPT2 outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Extracted hidden states using 'hidden_states[-1]'. Shape: torch.Size([16, 4, 768])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Flattened hidden states shape: torch.Size([16, 3072])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output before sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Output after sigmoid shape: torch.Size([16, 3600])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Final output shape after reshaping: torch.Size([16, 3, 40, 30])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def objective(trial):\n",
        "    avg_test_loss_lst = []\n",
        "    avg_train_loss_lst = []\n",
        "    learning_rate = trial.suggest_categorical('learning_rate',[1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6])\n",
        "    num_epochs = trial.suggest_int('num_epochs', 5, 20)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16])\n",
        "    num_layers_to_train = trial.suggest_categorical('num_layers_to_train', [1, 5, 10])\n",
        "    model = GPT2Model()\n",
        "    test_loss = training_loop(model, trial.params)[0]\n",
        "    return test_loss\n",
        "study = optuna.create_study(direction='minimize')\n",
        "# study.enqueue_trial(params = {'learning_rate': 0.1, 'num_epochs': 15, 'batch_size': 16, 'num_layers_to_train': 10})\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "best_trials = study.best_trials\n",
        "best_params = [param.params for param in best_trials][0]\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "model = GPT2Model()\n",
        "\n",
        "test_results = training_loop(model, best_params)[1]\n",
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQJYwy_3KKdE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#make sure test_results has what you want it to have\n",
        "#use the model you trained yesterday for the lidar data\n",
        "\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "# test_preds_lst = test_results['data'].values.tolist()\n",
        "# test_labels_lst = test_results['label'].values.tolist()\n",
        "\n",
        "# test_preds_tensor = torch.tensor(test_preds_lst)\n",
        "# test_labels_tensor = torch.tensor(test_labels_lst)\n",
        "# test_loss = BCEWithLogitsLoss(test_preds, test_labels)\n",
        "\n",
        "\n",
        "# accuracy = accuracy_score(test_labels_lst, test_preds_lst)\n",
        "# precision = precision_score(test_labels_lst, test_preds_lst)\n",
        "# recall = recall_score(test_labels_lst, test_preds_lst)\n",
        "# f1 = f1_score(test_labels_lst, test_preds_lst)\n",
        "# auc = roc_auc_score(test_labels_lst, test_preds_lst)\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "# print(f\"Recall: {recall}\")\n",
        "# print(f\"F1 Score: {f1}\")\n",
        "# print(f\"AUC Score: {auc}\")\n",
        "\n",
        "\n",
        "\n",
        "# test_loss"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7075523,
          "sourceId": 11780520,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}