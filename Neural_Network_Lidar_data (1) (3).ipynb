{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O37weyfV4ymT"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bO9sFQTw2cS5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "from typing import List, Dict, Union, Callable, Optional\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pdb\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jzeeTxri6Xci"
   },
   "outputs": [],
   "source": [
    "x_size = 120\n",
    "y_size = 90\n",
    "grid_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EPzbT6Ze3cui"
   },
   "outputs": [],
   "source": [
    "train_path = fr\"C:\\Users\\yuval\\training_batch_{grid_size}_meter_grid.pt\"\n",
    "labels_path = fr\"C:\\Users\\yuval\\label_batch_{grid_size}_meter_grid.pt\"\n",
    "\n",
    "train = torch.load(train_path)\n",
    "labels = torch.load(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIGi0sbF3dlR",
    "outputId": "a6df485e-10c7-427c-aecd-106ab94bb8fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([820, 120, 90])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_train_tensor(tensor):\n",
    "    \"\"\"\n",
    "    Processes a tensor based on the provided criteria.\n",
    "\n",
    "    Args:\n",
    "      tensor: The input tensor.\n",
    "\n",
    "    Returns:\n",
    "      A list of tensors.\n",
    "    \"\"\"\n",
    "    return (tensor[0, :, :]) / 1000\n",
    "processed_train = torch.empty(0,x_size, y_size)\n",
    "for i in range(train.size(0)):\n",
    "  new_train = process_train_tensor(train[i])\n",
    "  processed_train = torch.cat((processed_train, new_train.unsqueeze(0)), dim=0)\n",
    "processed_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RDWG11Lj55kR"
   },
   "outputs": [],
   "source": [
    "processed_labels = torch.empty(0,x_size, y_size)\n",
    "def process_labels(labels):\n",
    "  sample = labels.numpy()\n",
    "  # Assuming sample has shape (3, 40, 30)\n",
    "  max_values = np.max(sample, axis=0)\n",
    "  processed_labels = (max_values > 0).astype(int) # Check if any value in the 3 tensors is greater than 0\n",
    "  processed_labels = torch.tensor(processed_labels)\n",
    "  return processed_labels\n",
    "\n",
    "for i in range(labels.size(0)):\n",
    "  new = process_labels(labels[i])\n",
    "  processed_labels = torch.cat((processed_labels, new.unsqueeze(0)), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zgFbVQ169yw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 3\n",
    "batch_size = 16\n",
    "\n",
    "# Define the neural network architecture\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # Changed floating-point division to integer division\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Changed floating-point division to integer division\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = x_size * y_size\n",
    "hidden_size = x_size*y_size*32  # Adjust as needed\n",
    "output_size = x_size * y_size   # Binary classification (0 or 1)\n",
    "\n",
    "# Create the model\n",
    "model = SimpleClassifier(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(1000, dtype=torch.float32))  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(processed_train.float(), processed_labels.float())\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8QKONej7xvx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training loop with validation\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_epoch_loss = 0\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        # Get the actual batch size of the current batch\n",
    "        current_batch_size = data.size(0)\n",
    "        # Use the actual batch size for reshaping\n",
    "        target = target.view(current_batch_size, x_size, y_size).to(device)\n",
    "        outputs = model(data).view(current_batch_size, x_size, y_size).to(device)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "    train_loss_history.append(train_epoch_loss / len(train_loader))\n",
    "\n",
    "    val_epoch_loss = 0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            # Get the actual batch size of the current batch\n",
    "            current_batch_size = data.size(0)  # Add this line\n",
    "            # Use the actual batch size for reshaping\n",
    "            target = target.view(current_batch_size, x_size, y_size).to(device)  # Use current_batch_size\n",
    "            data = data.to(device)\n",
    "            outputs = model(data).view(current_batch_size, x_size, y_size).to(device)  # Use current_batch_size\n",
    "            loss = criterion(outputs, target)\n",
    "            val_epoch_loss += loss.item()\n",
    "    val_loss_history.append(val_epoch_loss / len(val_loader))\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_epoch_loss / len(train_loader):.4f}, Val Loss: {val_epoch_loss / len(val_loader):.4f}')\n",
    "\n",
    "# Plot the loss\n",
    "plt.plot(train_loss_history, label='Train Loss')\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxFYTJTj8Eiw"
   },
   "outputs": [],
   "source": [
    "# prompt: save SimpleClassifier state dict so I will be able to use it\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), fr'C:\\Users\\yuval\\simple_classifier_state_dict_(grid_size)_meters_grid.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBqzrDw-Sxcg"
   },
   "outputs": [],
   "source": [
    "# prompt: calculate accuracy, recall, precision\n",
    "\n",
    "# Evaluation on the validation set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        data = data.to(device)\n",
    "        # Get the actual batch size of the current batch\n",
    "        current_batch_size = data.size(0)\n",
    "        target = target.view(current_batch_size, x_size, y_size).to(device)\n",
    "\n",
    "        outputs = model(data).view(current_batch_size, x_size, y_size).to(device)\n",
    "\n",
    "        # Apply threshold to get binary predictions\n",
    "        predicted = (outputs > 0.07).int()\n",
    "\n",
    "        all_predictions.extend(predicted.cpu().numpy().flatten())\n",
    "        all_targets.extend(target.cpu().numpy().flatten())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "precision = precision_score(all_targets, all_predictions)\n",
    "recall = recall_score(all_targets, all_predictions)\n",
    "auc = roc_auc_score(all_targets, all_predictions)\n",
    "conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print (f\"AUC: {auc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
