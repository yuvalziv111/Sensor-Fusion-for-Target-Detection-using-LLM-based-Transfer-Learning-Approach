{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xso0niPJ6pB-"
   },
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.42.4\n",
    "# !pip install accelerate==0.32.1\n",
    "# !pip install torch==1.11.0\n",
    "# !pip install torchvision==0.12.0\n",
    "# !pip install mlflow=='2.15.1'\n",
    "# !pip install --upgrade scikit-learn numpy threadpoolctl\n",
    "# !pip install pyperclip\n",
    "# # !pip install databricks-vectorsearch\n",
    "# !pip install num2words\n",
    "# # pip install CloudPickle==3.0.0\n",
    "# !pip install optuna\n",
    "# !pip install grpcio==1.70.0\n",
    "# !pip install --force datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e8CK1nV_xpkp",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nuscenes-devkit' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  C:\\ProgramData\\anaconda3\\envs\\nuscenes_env\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  C:\\ProgramData\\anaconda3\\envs\\nuscenes_env\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  C:\\ProgramData\\anaconda3\\envs\\nuscenes_env\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  C:\\ProgramData\\anaconda3\\envs\\nuscenes_env\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  C:\\ProgramData\\anaconda3\\envs\\nuscenes_env\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "-e option requires 1 argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nuscenes-devkit in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (1.1.11)\n",
      "Requirement already satisfied: cachetools in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (5.5.2)\n",
      "Requirement already satisfied: descartes in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.1.0)\n",
      "Requirement already satisfied: fire in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (0.7.0)\n",
      "Requirement already satisfied: matplotlib<3.6.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.5.4.58 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (4.11.0.86)\n",
      "Requirement already satisfied: Pillow>6.2.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (11.2.1)\n",
      "Requirement already satisfied: pyquaternion>=0.9.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (0.9.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.13.1)\n",
      "Requirement already satisfied: Shapely<2.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.8.5.post1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (4.67.1)\n",
      "Requirement already satisfied: pycocotools>=2.0.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (2.0.8)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<3.6.0->nuscenes-devkit) (1.17.0)\n",
      "Requirement already satisfied: termcolor in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from fire->nuscenes-devkit) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from scikit-learn->nuscenes-devkit) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from scikit-learn->nuscenes-devkit) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from tqdm->nuscenes-devkit) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nuScenes-lidarseg (from versions: none)\n",
      "ERROR: No matching distribution found for nuScenes-lidarseg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.14.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (2.14.5)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (0.22.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: accelerate in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (14.0.2)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets==2.14.5) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from datasets==2.14.5) (6.0.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.5) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.5) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from aiohttp->datasets==2.14.5) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from aiohttp->datasets==2.14.5) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from aiohttp->datasets==2.14.5) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from aiohttp->datasets==2.14.5) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from aiohttp->datasets==2.14.5) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from aiohttp->datasets==2.14.5) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from aiohttp->datasets==2.14.5) (1.18.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from aiohttp->datasets==2.14.5) (5.0.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==2.14.5) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.14.5) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.14.5) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.14.5) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from tqdm>=4.62.1->datasets==2.14.5) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from pandas->datasets==2.14.5) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from pandas->datasets==2.14.5) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.14.5) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nuscenes-devkit in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (1.1.11)\n",
      "Requirement already satisfied: cachetools in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (5.5.2)\n",
      "Requirement already satisfied: descartes in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.1.0)\n",
      "Requirement already satisfied: fire in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (0.7.0)\n",
      "Requirement already satisfied: matplotlib<3.6.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.5.4.58 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (4.11.0.86)\n",
      "Requirement already satisfied: Pillow>6.2.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (11.2.1)\n",
      "Requirement already satisfied: pyquaternion>=0.9.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (0.9.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.13.1)\n",
      "Requirement already satisfied: Shapely<2.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (1.8.5.post1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (4.67.1)\n",
      "Requirement already satisfied: pycocotools>=2.0.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nuscenes-devkit) (2.0.8)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from matplotlib<3.6.0->nuscenes-devkit) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<3.6.0->nuscenes-devkit) (1.17.0)\n",
      "Requirement already satisfied: termcolor in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from fire->nuscenes-devkit) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from scikit-learn->nuscenes-devkit) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from scikit-learn->nuscenes-devkit) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from tqdm->nuscenes-devkit) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: open3d in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (1.24.3)\n",
      "Requirement already satisfied: dash>=2.6.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (3.0.4)\n",
      "Requirement already satisfied: werkzeug>=3.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (3.0.6)\n",
      "Requirement already satisfied: flask>=3.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (3.0.3)\n",
      "Requirement already satisfied: nbformat>=5.7.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (5.10.4)\n",
      "Requirement already satisfied: configargparse in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (1.7)\n",
      "Requirement already satisfied: ipywidgets>=8.0.4 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (8.1.5)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (6.0.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (4.13.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
      "Requirement already satisfied: retrying in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (72.1.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from flask>=3.0.0->open3d) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from flask>=3.0.0->open3d) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from werkzeug>=3.0.0->open3d) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from click>=8.1.3->flask>=3.0.0->open3d) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.21.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (1.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nbformat>=5.7.0->open3d) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (308)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (1.37.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from retrying->dash>=2.6.0->open3d) (1.17.0)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: open3d in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: pyvirtualdisplay in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (3.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (1.24.3)\n",
      "Requirement already satisfied: dash>=2.6.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (3.0.4)\n",
      "Requirement already satisfied: werkzeug>=3.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (3.0.6)\n",
      "Requirement already satisfied: flask>=3.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (3.0.3)\n",
      "Requirement already satisfied: nbformat>=5.7.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (5.10.4)\n",
      "Requirement already satisfied: configargparse in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (1.7)\n",
      "Requirement already satisfied: ipywidgets>=8.0.4 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from open3d) (8.1.5)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (6.0.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (4.13.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
      "Requirement already satisfied: retrying in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from dash>=2.6.0->open3d) (72.1.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from flask>=3.0.0->open3d) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from flask>=3.0.0->open3d) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from werkzeug>=3.0.0->open3d) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from click>=8.1.3->flask>=3.0.0->open3d) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.21.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (1.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nbformat>=5.7.0->open3d) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (308)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (1.37.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from retrying->dash>=2.6.0->open3d) (1.17.0)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p /data/sets/nuscenes  # Make the directory to store the nuScenes dataset in.\n",
    "\n",
    "# !wget https://www.nuscenes.org/data/v1.0-mini.tgz  # Download the nuScenes mini split.\n",
    "\n",
    "# !tar -xf v1.0-mini.tgz -C /data/sets/nuscenes  # Uncompress the nuScenes mini split.\n",
    "\n",
    "# !pip install nuscenes-devkit &> /dev/null  # Install nuScenes.\n",
    "\n",
    "import os\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/nutonomy/nuscenes-devkit.git\n",
    "\n",
    "# Check if the directory exists before changing to it\n",
    "if os.path.isdir('nuscenes-devkit'):\n",
    "    os.chdir('nuscenes-devkit')\n",
    "    %pip install -e\n",
    "    %pip install nuscenes-devkit &> /dev/null\n",
    "    %pip install nuscenes-devkit\n",
    "    %pip install nuScenes-lidarseg\n",
    "else:\n",
    "    print(\"Directory 'nuscenes-devkit' does not exist.\")\n",
    "\n",
    "# !wget https://www.nuscenes.org/data/v1.0-mini.tgz  # Download the nuScenes mini split.\n",
    "# !wget https://www.nuscenes.org/data/nuScenes-lidarseg-mini-v1.0.tar.bz2\n",
    "\n",
    "# !tar -xf v1.0-mini.tgz -C /data/sets/nuscenes  # Uncompress the nuScenes mini split.\n",
    "# !tar -xf nuScenes-panoptic-v1.0-mini.tar.gz -C /data/sets/nuscenes   # Uncompress the Panoptic nuScenes mini split.\n",
    "\n",
    "%pip install datasets==2.14.5 torch torchvision torchaudio accelerate\n",
    "%pip install nuscenes-devkit\n",
    "%pip install open3d\n",
    "%pip install open3d pyvirtualdisplay\n",
    "# %pip install open3d matplotlib\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "from sklearn.decomposition import PCA\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import json\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "from typing import List, Dict, Union, Callable, Optional\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from pyquaternion import Quaternion\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.scripts.export_kitti import transform_matrix\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, RadarPointCloud, Box\n",
    "from pyquaternion import Quaternion\n",
    "import pdb\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "import cv2\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "import torch\n",
    "import open3d as o3d\n",
    "from pyquaternion import Quaternion\n",
    "import pdb\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCELoss\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "asgRDELXqGZq"
   },
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "files_dir = \"D:/Nuscenes/unified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVEH3y396xtq"
   },
   "source": [
    "# **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration\n",
    "num_objects = 3\n",
    "x_size = 120\n",
    "y_size = 90\n",
    "grid_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "detector = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\", device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KP9ILY1RtRA9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_camera_point_using_pnhole(ann, sensor_channel):\n",
    "  # Retrieve the camera calibration information\n",
    "  sensor_data = nusc.get('sample_data',my_sample['data'][sensor_channel])\n",
    "  cam_intrinsic = nusc.get('calibrated_sensor', sensor_data['calibrated_sensor_token'])\n",
    "  #calculate distance function\n",
    "  cam_intrinsic = np.array(nusc.get('calibrated_sensor', sensor_data['calibrated_sensor_token'])['camera_intrinsic'])\n",
    "  fx = cam_intrinsic[0][0]\n",
    "  fy = cam_intrinsic[1][1]\n",
    "  cx = cam_intrinsic[0][2]\n",
    "  cy = cam_intrinsic[1][2]\n",
    "  # Extract truck width statistics\n",
    "  car_stats = stats[\"vehicle.car\"]\n",
    "  truck_stats = stats[\"vehicle.truck\"]\n",
    "  person_stats = stats[\"human.pedestrian.adult\"]\n",
    "  avg_width_meters = {\"\"}\n",
    "  avg_car_width_meters = float(car_stats[\"width\"].split(\"±\")[0])\n",
    "  avg_truck_width_meters = float(truck_stats[\"width\"].split(\"+-\")[0])\n",
    "  avg_person_width_meters = float(person_stats[\"width\"].split(\"±\")[0])\n",
    "  x_pixel = ann['xmax'] - ann['xmin']\n",
    "  y_pixel = ann['ymax'] - ann['ymin']\n",
    "  center_y_pixel = (ann['ymax'] + ann['ymin']) / 2\n",
    "  center_x_pixel = (ann['xmax'] + ann['xmin']) / 2\n",
    "  if ann['object']==\"person\":\n",
    "    z_camera = (fx * width_stats['human.pedestrian.adult']) / x_pixel\n",
    "  else:\n",
    "    z_camera = (fx * width_stats['vehicle.'+ann['object']]) / x_pixel\n",
    "  x_camera = (z_camera * (center_x_pixel - cx)) / fx\n",
    "  y_camera = (z_camera * (center_y_pixel - cy)) / fy\n",
    "\n",
    "  #transform the points into the lidar axis\n",
    "  transformation_matrix = np.array([[1, 0, 0], [0, 0, 1], [0, -1, 0]])\n",
    "  object_location_camera_transposed = np.array([x_camera, y_camera, z_camera]).reshape(3, 1)\n",
    "  result = np.dot(transformation_matrix, object_location_camera_transposed)\n",
    "  camera_to_lidar = result.T.reshape(num_objects)\n",
    "\n",
    "  # Return a Series instead of individual values\n",
    "  return pd.Series({'camera_point_x': camera_to_lidar[0], 'camera_point_y': camera_to_lidar[1], 'camera_point_z': camera_to_lidar[2]})\n",
    "\n",
    "\n",
    "def generate_potential_annotations(sensor_name):\n",
    "  global detector\n",
    "  #Load the sensor data from NuScenes\n",
    "  sensor_data = nusc.get('sample_data', my_sample['data'][sensor_name])\n",
    "  # Get the image file path\n",
    "  image_filepath = sensor_data['filename']\n",
    "  image_fullpath = os.path.join(nusc.dataroot, image_filepath)\n",
    "  # Check if the image file exists\n",
    "  if not os.path.exists(image_fullpath):\n",
    "      print(fr\"The file {image_fullpath} does not exist at the provided path.\")\n",
    "      not_found_files.append(image_fullpath)\n",
    "      return None\n",
    "  else:\n",
    "      # Read the image\n",
    "      image = cv2.imread(image_fullpath)\n",
    "    \n",
    "      # Display the image\n",
    "      # cv2_imshow(image)\n",
    "  ################################\n",
    "  # Load the model for detecting potential annotations\n",
    "\n",
    "  \n",
    "  # Convert the NumPy array to a PIL Image object\n",
    "  image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) #added color conversion\n",
    "\n",
    "  # Perform object detection\n",
    "  results = detector(image_pil)\n",
    "\n",
    "  # Create a copy of the image for drawing bounding boxes\n",
    "  image_with_boxes = image.copy()\n",
    "\n",
    "  # Iterate through the results and draw bounding boxes\n",
    "  for result in results:\n",
    "      xmin_normalized = result['box']['xmin']\n",
    "      ymin_normalized = result['box']['ymin']\n",
    "      xmax_normalized = result['box']['xmax']\n",
    "      ymax_normalized = result['box']['ymax']\n",
    "\n",
    "      # Denormalize the bounding box coordinates\n",
    "      image_height, image_width, _ = image.shape #get image dimensions\n",
    "      xmin = int(xmin_normalized * image_width)\n",
    "      ymin = int(ymin_normalized * image_height)\n",
    "      xmax = int(xmax_normalized * image_width)\n",
    "      ymax = int(ymax_normalized * image_height)\n",
    "\n",
    "      # Draw the bounding box and label on the image\n",
    "#       cv2.rectangle(image_with_boxes, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "#       cv2.putText(image_with_boxes, f\"{result['label']}: {result['score']:.2f}\", (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "  #########################\n",
    "    # Load the image object detection pipeline - note the hyphen instead of underscore\n",
    "\n",
    "\n",
    "  # Convert the NumPy array to a PIL Image object\n",
    "  image_pil = Image.fromarray(image)\n",
    "\n",
    "  # Perform object detection on the PIL Image object\n",
    "  results = detector(image_pil)  # Pass the PIL Image\n",
    "\n",
    "  potential_annotations = pd.DataFrame()\n",
    "\n",
    "  # Optionally, visualize the results (requires OpenCV)\n",
    "  image_with_boxes = image.copy()  # Continue using the NumPy array for visualization\n",
    "  for result in results:\n",
    "      xmin_normalized = result['box']['xmin']\n",
    "      ymin_normalized = result['box']['ymin']\n",
    "      xmax_normalized = result['box']['xmax']\n",
    "      ymax_normalized = result['box']['ymax']\n",
    "      # # Denormalize the bounding box coordinates\n",
    "      # xmin_pixel = int(xmin_normalized * 1600)\n",
    "      # ymin_pixel = int(ymin_normalized * 900)\n",
    "      # xmax_pixel = int(xmax_normalized * 1600)\n",
    "      # ymax_pixel = int(ymax_normalized * 900)\n",
    "\n",
    "      result_df = pd.DataFrame([{\"object\": result['label'],\n",
    "                                \"confidence\": result['score'],\n",
    "                                \"xmin\": xmin_normalized,\n",
    "                                \"ymin\": ymin_normalized,\n",
    "                                \"xmax\": xmax_normalized,\n",
    "                                \"ymax\": ymax_normalized}])\n",
    "      potential_annotations = pd.concat([potential_annotations, result_df])\n",
    "#       cv2.rectangle(image_with_boxes, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "#       cv2.putText(image_with_boxes, f\"{result['label']}: {result['score']:.2f}\", (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "  #########################\n",
    "  ###preprocess potential annotations\n",
    "  # Display the image with bounding boxes\n",
    "  #process the data so it will be suitable to the format, select only people and vechiles\n",
    "  potential_annotations.reset_index(inplace = True, drop = True)\n",
    "  if potential_annotations.shape[0] ==0:\n",
    "    return pd.DataFrame()\n",
    "  potential_annotations['height'] = potential_annotations['ymax'] - potential_annotations['ymin']\n",
    "\n",
    "  potential_annotations['width'] = potential_annotations['xmax'] - potential_annotations['xmin']\n",
    "  potential_annotations['num_pixels'] = potential_annotations['height'] * potential_annotations['width']\n",
    "  potential_annotations = potential_annotations[potential_annotations['object'].isin(['car', 'truck', 'person'])]\n",
    "  potential_annotations.head()\n",
    "  potential_annotations.sort_values(by = 'confidence', ascending = False).head()\n",
    "  sample_token = nusc.get('sample_data', sensor_data['token'])['sample_token']\n",
    "  ground_truth_annotation_keys= nusc.get('sample', sample_token)['anns']\n",
    "\n",
    "  potential_annotations = potential_annotations[potential_annotations['object'].isin([\"car\", \"truck\", \"person\"])]\n",
    "  # Apply the function and assign the resulting columns\n",
    "  try:\n",
    "      potential_annotations[['camera_point_x', 'camera_point_y', 'camera_point_z']] = potential_annotations.apply(lambda x: calc_camera_point_using_pnhole(x, sensor_data['channel']), axis=1)\n",
    "  except ValueError:\n",
    "    if potential_annotations.shape[0] < 1 :\n",
    "        print (fr\"No detections for image {image_fullpath}\")\n",
    "  potential_annotations['sensor_channel'] = sensor_data['channel']\n",
    "  return potential_annotations\n",
    "\n",
    "def cartesian_to_polar(x, y, z):\n",
    "  \"\"\"Converts Cartesian coordinates to polar coordinates (translation and rotation).\n",
    "\n",
    "  Args:\n",
    "    x: x-coordinate.\n",
    "    y: y-coordinate.\n",
    "    z: z-coordinate.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing the translation (distance) and rotation (azimuth and elevation).\n",
    "  \"\"\"\n",
    "\n",
    "  distance = np.sqrt(x**2 + y**2 + z**2)\n",
    "  azimuth = np.arctan2(y, x)\n",
    "  elevation = np.arctan2(z, np.sqrt(x**2 + y**2))\n",
    "\n",
    "  return {'distance': distance, 'azimuth': azimuth, 'elevation': elevation}\n",
    "\n",
    "def points_in_box(box: 'Box', points: np.ndarray, wlh_factor: float = 1.0):\n",
    "    \"\"\"\n",
    "    Checks whether points are inside the box.\n",
    "    Picks one corner as reference (p1) and computes the vector to a target point (v).\n",
    "    Then for each of the 3 axes, project v onto the axis and compare the length.\n",
    "    Inspired by: https://math.stackexchange.com/a/1552579\n",
    "    :param box: <Box>.\n",
    "    :param points: <np.float: 3, n>.\n",
    "    :param wlh_factor: Inflates or deflates the box.\n",
    "    :return: <np.bool: n, >.\n",
    "    \"\"\"\n",
    "    corners = box.corners(wlh_factor=wlh_factor)\n",
    "\n",
    "    p1 = corners[:, 0]\n",
    "    p_x = corners[:, 4]\n",
    "    p_y = corners[:, 1]\n",
    "    p_z = corners[:, 3]\n",
    "\n",
    "    i = p_x - p1\n",
    "    j = p_y - p1\n",
    "    k = p_z - p1\n",
    "\n",
    "    v = points - p1.reshape((-1, 1))\n",
    "\n",
    "    iv = np.dot(i, v)\n",
    "    jv = np.dot(j, v)\n",
    "    kv = np.dot(k, v)\n",
    "\n",
    "    mask_x = np.logical_and(0 <= iv, iv <= np.dot(i, i))\n",
    "    mask_y = np.logical_and(0 <= jv, jv <= np.dot(j, j))\n",
    "    mask_z = np.logical_and(0 <= kv, kv <= np.dot(k, k))\n",
    "    mask = np.logical_and(np.logical_and(mask_x, mask_y), mask_z)\n",
    "\n",
    "    return mask\n",
    "\n",
    "###convert camera point to lidar point\n",
    "def convert_cam_to_lidar(sample, camera_direction, point_to_convert):\n",
    "  camera_rec = nusc.get('sample_data', sample['data'][camera_direction])\n",
    "  camera_cs = nusc.get('calibrated_sensor', camera_rec['calibrated_sensor_token'])\n",
    "  lidar_rec = nusc.get('sample_data', sample['data'][camera_direction])\n",
    "  lidar_cs = nusc.get('calibrated_sensor', lidar_rec['calibrated_sensor_token'])\n",
    "\n",
    "  ego_pose = nusc.get('ego_pose', camera_rec['ego_pose_token'])\n",
    "  ##create camerara extrinsic matrix\n",
    "  translation_vector = np.array(camera_cs['translation'])\n",
    "  rotation_matrix =R.from_quat(camera_cs['rotation']).as_matrix()\n",
    "  extrinsic_matrix = np.eye(4)\n",
    "  extrinsic_matrix[:3, :3] = rotation_matrix\n",
    "  ###transform to the vehicle crdinates\n",
    "  point_vehicle = extrinsic_matrix @ point_to_convert\n",
    "  ###transform to the lidar coordinates\n",
    "  T_lidar = np.eye(4)\n",
    "  T_lidar[:3, :3] = R.from_quat(lidar_cs['rotation']).as_matrix()\n",
    "  T_lidar[:3, 3] = lidar_cs['translation']\n",
    "  T_lidar_inv = np.linalg.inv(T_lidar)\n",
    "  point_lidar = T_lidar_inv @ point_vehicle\n",
    "  return point_lidar[:3]\n",
    "# a = convert_cam_to_lidar(my_sample, \"CAM_FRONT\", np.array([potential_annotations.loc[17]['camera_point_x'], potential_annotations.loc[17]['camera_point_y'], potential_annotations.loc[17]['camera_point_z'], 1]))\n",
    "\n",
    "\n",
    "def create_grid_map_lidar(ground_truth, grid_size=grid_size):\n",
    "    \"\"\"\n",
    "    Creates a grid map from ground truth point cloud data.\n",
    "\n",
    "    Args:\n",
    "        ground_truth: Pandas DataFrame containing 'x', 'y', 'z', and 'intensity' columns.\n",
    "        grid_size: Size of each grid cell in meters (default: 3).\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the grid map, where each cell contains the average intensity.\n",
    "    \"\"\"\n",
    "    if ground_truth.empty or ground_truth['x'].isna().all() or ground_truth['y'].isna().all():\n",
    "        print(\"Warning: Ground truth data contains no valid coordinates\")\n",
    "        return None\n",
    "    # Find min/max coordinates\n",
    "    min_x = ground_truth['x'].min()\n",
    "    max_x = ground_truth['x'].max()\n",
    "    min_y = ground_truth['y'].min()\n",
    "    max_y = ground_truth['y'].max()\n",
    "    \n",
    "#     print (\"max_x: \",max_x)\n",
    "#     print (\"min_x: \",min_x)\n",
    "#     print (\"grid_size: \",grid_size)\n",
    "#     # Calculate grid dimensions\n",
    "#     display(\"grid_size: \", grid_size)\n",
    "#     display(\"max_x: \", max_x)\n",
    "#     display(\"min_x: \", min_x)\n",
    "#     display(\"max_x type:\", type(max_x))\n",
    "#     display(\"min_x type:\", type(min_x))\n",
    "#     display(\"max_x - min_x:\", max_x - min_x)\n",
    "    x_dim = int(np.ceil((max_x - min_x) / grid_size))\n",
    "    y_dim = int(np.ceil((max_y - min_y) / grid_size))\n",
    "\n",
    "    # Initialize the grid map\n",
    "    grid_map = np.zeros((y_dim, x_dim))\n",
    "\n",
    "    # Iterate over the points and populate the grid map\n",
    "    for index, row in ground_truth.iterrows():\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        intensity = row['intensity']\n",
    "\n",
    "        # Calculate grid cell indices\n",
    "        grid_x = int(np.floor((x - min_x) / grid_size))\n",
    "        grid_y = int(np.floor((y - min_y) / grid_size))\n",
    "\n",
    "        # Check bounds\n",
    "        if 0 <= grid_x < x_dim and 0 <= grid_y < y_dim:\n",
    "            # Accumulate intensity values in the grid cell\n",
    "            grid_map[grid_y, grid_x] += intensity\n",
    "\n",
    "    # Calculate average intensity for each cell\n",
    "    point_counts = np.zeros_like(grid_map)\n",
    "\n",
    "    for index, row in ground_truth.iterrows():\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "\n",
    "        # Calculate grid cell indices\n",
    "        grid_x = int(np.floor((x - min_x) / grid_size))\n",
    "        grid_y = int(np.floor((y - min_y) / grid_size))\n",
    "\n",
    "        # Check bounds\n",
    "        if 0 <= grid_x < x_dim and 0 <= grid_y < y_dim:\n",
    "            point_counts[grid_y, grid_x] += 1\n",
    "    grid_map = np.divide(grid_map, point_counts, out=np.zeros_like(grid_map), where=point_counts!=0) # handle divide by zero\n",
    "    return grid_map\n",
    "\n",
    "def create_grid_map(potential_annotations, grid_size=3, object_type=None):\n",
    "    \"\"\"\n",
    "    Creates a grid map from object detection data.\n",
    "\n",
    "    Args:\n",
    "        potential_annotations: Pandas DataFrame with 'camera_point_x', 'camera_point_y', and 'object' columns.\n",
    "        grid_size: Size of each grid cell in meters.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the grid map.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find min/max coordinates\n",
    "#     display(\"potential_annotations: \", potential_annotations)\n",
    "    min_x = potential_annotations['camera_point_x'].min()\n",
    "    max_x = potential_annotations['camera_point_x'].max()\n",
    "    min_y = potential_annotations['camera_point_y'].min()\n",
    "    max_y = potential_annotations['camera_point_y'].max()\n",
    "    # Calculate grid dimensions\n",
    "    x_dim = int(np.ceil((max_x - min_x) / grid_size))\n",
    "    y_dim = int(np.ceil((max_y - min_y) / grid_size))\n",
    "\n",
    "    # Initialize the grid map\n",
    "    grid_map = np.empty((y_dim, x_dim), dtype=object)  # Use object dtype to store strings\n",
    "    grid_map[:] = 0  # Initialize with empty strings\n",
    "\n",
    "    \n",
    "    potential_annotations = potential_annotations[potential_annotations['object'] == object_type.split('_')[-1]]\n",
    "    if len(potential_annotations) < 1:\n",
    "        return torch.zeros(x_size, y_size)\n",
    "    # Iterate through the detections\n",
    "    for _, row in potential_annotations.iterrows():\n",
    "        if len(potential_annotations) ==0:\n",
    "            grid_map = np.zeros(x_dim, y_dim)\n",
    "            return grid_map\n",
    "        x = row['camera_point_x']\n",
    "        y = row['camera_point_y']\n",
    "        obj_cols = row[-3:]\n",
    "        obj = obj_cols[obj_cols == 1].index[0].split(\"_\")[1]\n",
    "        confidence = row['confidence'] # Extract the confidence value as a float\n",
    "\n",
    "        # Calculate grid cell indices\n",
    "        grid_x = int(np.floor((x - min_x) / grid_size))\n",
    "        grid_y = int(np.floor((y - min_y) / grid_size))\n",
    "\n",
    "        # Check bounds\n",
    "        if 0 <= grid_x < x_dim and 0 <= grid_y < y_dim:\n",
    "            # If the cell is empty or the current object has higher confidence\n",
    "            if grid_map[grid_y, grid_x] == 0 or confidence > grid_map[grid_y, grid_x]: # Compare confidence values directly\n",
    "                grid_map[grid_y, grid_x] = confidence\n",
    "        print (fr\"map for {object_type.split('_')[-1]}\")\n",
    "#     plot_optical_grid_map(grid_map)\n",
    "    return grid_map\n",
    "\n",
    "def create_ground_truth_map(ground_truth, grid_size=grid_size):\n",
    "    \"\"\"\n",
    "    Creates a ground truth grid map from object detection data.\n",
    "\n",
    "    Args:\n",
    "        ground_truth: Pandas DataFrame with 'x', 'y', and 'label' columns.\n",
    "        grid_size: Size of each grid cell in meters.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the ground truth grid map.\n",
    "    \"\"\"\n",
    "    if ground_truth.empty or ground_truth['x'].isna().all() or ground_truth['y'].isna().all():\n",
    "        print(\"Warning: Ground truth data contains no valid coordinates\")\n",
    "        return None, None\n",
    "    # Find min/max coordinates\n",
    "    \n",
    "    min_x = ground_truth['x'].min()\n",
    "    max_x = ground_truth['x'].max()\n",
    "    min_y = ground_truth['y'].min()\n",
    "    max_y = ground_truth['y'].max()\n",
    "#     print (\"max_x: \",max_x)\n",
    "#     print (\"min_x: \",min_x)\n",
    "#     print (\"grid_size: \",grid_size)\n",
    "    # Calculate grid dimensions\n",
    "#     display(\"grid_size: \", grid_size)\n",
    "#     display(\"max_x: \", max_x)\n",
    "#     display(\"min_x: \", min_x)\n",
    "#     display(\"max_x type:\", type(max_x))\n",
    "#     display(\"min_x type:\", type(min_x))\n",
    "#     display(\"max_x - min_x:\", max_x - min_x)\n",
    "    # Calculate grid dimensions\n",
    "    x_dim = int(np.ceil((max_x - min_x) / grid_size))\n",
    "    y_dim = int(np.ceil((max_y - min_y) / grid_size))\n",
    "\n",
    "    # Get unique object labels\n",
    "    unique_labels = {\"truck\": 0, \"car\":1, \"person\":2}\n",
    "    \n",
    "    num_objects = len(unique_labels)\n",
    "\n",
    "    # Initialize the ground truth grid map (one map per object)\n",
    "    ground_truth_map = np.zeros((num_objects, y_dim, x_dim), dtype=int)\n",
    "\n",
    "    # Iterate through the detections\n",
    "    for _, row in ground_truth.iterrows():\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        label = row['label']\n",
    "\n",
    "        # Calculate grid cell indices\n",
    "        grid_x = int(np.floor((x - min_x) / grid_size))\n",
    "        grid_y = int(np.floor((y - min_y) / grid_size))\n",
    "\n",
    "        # Check bounds\n",
    "        if 0 <= grid_x < x_dim and 0 <= grid_y < y_dim:\n",
    "            # Find the object index\n",
    "            object_index = unique_labels[label]\n",
    "            # Mark the cell as occupied for the corresponding object\n",
    "            ground_truth_map[object_index, grid_y, grid_x] = 1\n",
    "            \n",
    "    return ground_truth_map, unique_labels\n",
    "\n",
    "def pad_tensor_to_target(tensor, target_shape):\n",
    "    \"\"\"\n",
    "    Pads a 3D tensor to a target shape using torch.nn.functional.pad, focusing on the last two dimensions.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The 3D tensor to pad.\n",
    "        target_shape (tuple): The desired shape of the padded tensor (target_depth, target_height, target_width).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The padded tensor.\n",
    "    \"\"\"\n",
    "    if len(tensor.shape) == 2:\n",
    "        tensor = tensor.unsqueeze(0)  # Add batch dimension\n",
    "    tensor_depth, tensor_height, tensor_width = tensor.shape\n",
    "    target_depth, target_height, target_width = target_shape\n",
    "\n",
    "    pad_height_before = (target_height - tensor_height) // 2\n",
    "    pad_height_after = target_height - tensor_height - pad_height_before\n",
    "\n",
    "    pad_width_before = (target_width - tensor_width) // 2\n",
    "    pad_width_after = target_width - tensor_width - pad_width_before\n",
    "\n",
    "    pad_depth_before = (target_depth - tensor_depth) // 2\n",
    "    pad_depth_after = target_depth - tensor_depth - pad_depth_before\n",
    "\n",
    "    padding = (pad_width_before, pad_width_after, pad_height_before, pad_height_after, pad_depth_before, pad_depth_after)\n",
    "\n",
    "    # Pad the last three dimensions (height, width, depth)\n",
    "    padded_tensor = F.pad(tensor, (pad_width_before, pad_width_after, pad_height_before, pad_height_after, pad_depth_before, pad_depth_after))\n",
    "\n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKGu7KYHl-MD"
   },
   "source": [
    "### Application of the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rARi8bwOwjYy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c610d0ac2e2045a5972bda66ac42ede3', 'ea0979999bf84ee6a6230b1bde7ec723', 'b2119bd765a94b0cb705424800307bbf', '270fe8382f884386b3445143fa946200', '32bae098e2434a09af1e7983e31fbf5c', '2bfb95d8ba3a4c11869f4d6635784640', '29dee0b8210b410a9b3421f0cb39019f', '69a38ccf0894467fbae658d28d4fd10a', '34a9823fac0d4b9db30898e00b5f9f9c', 'faa975eaad804c85bd8f2da9b30c8d9a', 'd4d2faa310a748dda508d15c6d5c4244', '7bbc6931b39b4ba3834240618fc4a4c2', 'fee7ac5f5c1e4943877cd20d6e069427', '797700339b014fb6aa61c1ea3778d587', 'd9161e521b1644cea4cb9e3f21ef9f79', '19640fe4b6894f97b16e0faad51432b4', '2a334f5c4615465f86a250d4758a2d7d', 'f634de95cc7043b8b38ceaac67d472cf', '8d8728879b89405eba3f8ce1af138cb2', '4f679c8f8f6d4f5d8466253dda4733ba', 'cd9db61edff14e8784678abb347cd674', '2175d0e84f224ea69907e5c338bde395', '9544516643a14926bf750fc71c1b307d', 'e631037169574c67944176bf079ee75c', 'bc5daf905b854dbc8944811c4b7c319d', '390f81ac97474695a727d688240e6fba', '4ed628299b1e45a3a73704e8cf8287a9', 'add2303ca41d445c8339e05769745fc0', '2376fcdd28a44b83962289664cee55b7', '16c90eedfc7943a5a4c64e84d18876a2', '102b894332464704900264216480a8f7', 'bfe368f8c6a44efcb323a82f6974a9a6', '034dee1695304630b0692da8c1f153fc', '7052d21b95fc4bae8761b8d9524f3e42', 'e8099a6136804f3bb9b38ff94d98eb64', 'e6f1a7e6218a4737bfedc6af90926b3e', '6af9b75e439e4811ad3b04dc2220657a', 'f97bf749746c4c3a8ad9f1c11eab6444', 'bd338b912ce9434995b29b6dac9fbf1d']\n"
     ]
    }
   ],
   "source": [
    "# # Define the file path\n",
    "# file_path = r\"D:\\Nuscenes\\required scenes.txt\"\n",
    "\n",
    "# # Initialize an empty list to store the rows\n",
    "# scenes_list = []\n",
    "\n",
    "# # Open and read the file\n",
    "# with open(file_path, 'r') as file:\n",
    "#     # Read each line and add it to the list\n",
    "#     for line in file:\n",
    "#         # Strip whitespace and newline characters\n",
    "#         scenes_list.append(line.strip())\n",
    "scenes_list = ['c610d0ac2e2045a5972bda66ac42ede3', 'ea0979999bf84ee6a6230b1bde7ec723', \"b2119bd765a94b0cb705424800307bbf\", \n",
    "              '270fe8382f884386b3445143fa946200', '32bae098e2434a09af1e7983e31fbf5c', '2bfb95d8ba3a4c11869f4d6635784640', '29dee0b8210b410a9b3421f0cb39019f', \n",
    "               '69a38ccf0894467fbae658d28d4fd10a', '34a9823fac0d4b9db30898e00b5f9f9c','faa975eaad804c85bd8f2da9b30c8d9a','d4d2faa310a748dda508d15c6d5c4244','7bbc6931b39b4ba3834240618fc4a4c2','fee7ac5f5c1e4943877cd20d6e069427','797700339b014fb6aa61c1ea3778d587','d9161e521b1644cea4cb9e3f21ef9f79','19640fe4b6894f97b16e0faad51432b4','2a334f5c4615465f86a250d4758a2d7d','f634de95cc7043b8b38ceaac67d472cf','8d8728879b89405eba3f8ce1af138cb2','4f679c8f8f6d4f5d8466253dda4733ba','cd9db61edff14e8784678abb347cd674','2175d0e84f224ea69907e5c338bde395','9544516643a14926bf750fc71c1b307d','e631037169574c67944176bf079ee75c','bc5daf905b854dbc8944811c4b7c319d','390f81ac97474695a727d688240e6fba','4ed628299b1e45a3a73704e8cf8287a9','add2303ca41d445c8339e05769745fc0','2376fcdd28a44b83962289664cee55b7','16c90eedfc7943a5a4c64e84d18876a2','102b894332464704900264216480a8f7','bfe368f8c6a44efcb323a82f6974a9a6','034dee1695304630b0692da8c1f153fc','7052d21b95fc4bae8761b8d9524f3e42','e8099a6136804f3bb9b38ff94d98eb64','e6f1a7e6218a4737bfedc6af90926b3e','6af9b75e439e4811ad3b04dc2220657a','f97bf749746c4c3a8ad9f1c11eab6444','bd338b912ce9434995b29b6dac9fbf1d' ]\n",
    "# Print the list to verify\n",
    "print(scenes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 77.542 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 16.2 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version='v1.0-trainval', dataroot=files_dir, verbose=True)\n",
    "scenes_df = pd.DataFrame(scenes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QlOfcxSbmEFA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ נמצא קובץ שמירה. טוען התקדמות מ: nuscenes_checkpoint1.pth\n",
      "הריצה תמשיך מסצנה מספר 38.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scenes:   3%|█▋                                                              | 1/39 [00:00<00:00, 51.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "import logging\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "from nuscenes.utils.geometry_utils import points_in_box\n",
    "import transformers\n",
    "\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*copying from a non-meta parameter.*\", category=UserWarning)\n",
    "# sensor_data = nusc.get('sample_data',my_sample['data'][sensor_channel])\n",
    "\n",
    "# --- הגדרות CHECKPOINT ---\n",
    "# 1. נגדיר כל כמה דגימות (samples) נרצה לשמור את ההתקדמות\n",
    "SAVE_EVERY_N_SAMPLES = 20  # לדוגמה, שמירה כל 20 דגימות\n",
    "# 2. נגדיר את שם קובץ השמירה\n",
    "CHECKPOINT_PATH = 'nuscenes_checkpoint1.pth'\n",
    "\n",
    "# Suppress warnings and logs\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*copying from a non-meta parameter.*\", category=UserWarning)\n",
    "\n",
    "# --- לוגיקת טעינת CHECKPOINT ---\n",
    "# נבדוק אם קובץ השמירה קיים לפני שמתחילים את הלולאה\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"✅ נמצא קובץ שמירה. טוען התקדמות מ: {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    \n",
    "    # טעינת כל המשתנים השמורים\n",
    "    scene_idx = checkpoint['scene_idx']\n",
    "    next_scene = checkpoint['next_scene']\n",
    "    training_batch = checkpoint['training_batch']\n",
    "    label_batch = checkpoint['label_batch']\n",
    "    logs = checkpoint['logs']\n",
    "    not_found_files = checkpoint['not_found_files']\n",
    "    scenes_with_missing_files = checkpoint['scenes_with_missing_files']\n",
    "    \n",
    "    # נקבע את נקודת ההתחלה של מד ההתקדמות\n",
    "    pbar_initial = scene_idx\n",
    "    print(f\"הריצה תמשיך מסצנה מספר {scene_idx}.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ לא נמצא קובץ שמירה. מתחיל ריצה חדשה מההתחלה.\")\n",
    "    # אתחול המשתנים כפי שהיו בקוד המקורי\n",
    "    training_batch = torch.empty(0, num_objects + 1, x_size, y_size)\n",
    "    label_batch = torch.empty(0, num_objects, x_size, y_size)\n",
    "    logs = {}\n",
    "    not_found_files = []\n",
    "    scenes_with_missing_files = []\n",
    "    scene_idx = 0\n",
    "    next_scene = None\n",
    "    pbar_initial = 0\n",
    "\n",
    "# Add progress bar for the main loop\n",
    "total_scenes = scenes_df.shape[0]\n",
    "with tqdm(total=total_scenes, desc=\"Processing scenes\") as pbar:\n",
    "    while scene_idx < scenes_df.shape[0]:\n",
    "        token_idx = scenes_df.iloc[scene_idx,0]\n",
    "        logging.getLogger(\"torch.device\").setLevel(logging.ERROR)\n",
    "        my_scene = nusc.get(\"scene\",token_idx )\n",
    "        if next_scene is None:\n",
    "            display(\"my scene: \", my_scene)\n",
    "            sample_token = my_scene['first_sample_token']\n",
    "        elif next_scene == '':\n",
    "            scene_idx += 1\n",
    "            next_scene = None\n",
    "            pbar.update(1)  # Update progress bar when moving to next scene\n",
    "            continue\n",
    "        else:\n",
    "            sample_token = next_scene\n",
    "        print (\"current scene is: \", my_scene)\n",
    "        print (\"description: \", my_scene['description'])\n",
    "        print (\"current sample_token: \", sample_token)\n",
    "        #if we are in the last sample_token of a scene then there will be a keyerror\n",
    "        my_sample = nusc.get('sample', sample_token)\n",
    "        ###################################################\n",
    "        #create a dictionary of objects stats\n",
    "        stats = {\n",
    "            \"vehicle.truck\":{\"width\":\"2.35+-0.34\",'len': \"6.50±1.56\", \"height\": \"2.62±0.68\", \"lw_aspect\": \"2.75±0.37\"},\n",
    "                \"vehicle.car\":{\"width\":\"1.92±0.16\",'len': \"4.62±0.36\", \"height\": \"1.69±0.21\", \"lw_aspect\": \"2.41±0.18\"},\n",
    "                \"human.pedestrian.adult\":{\"width\":\"0.68±0.11\", \"len\": \"0.73±0.17\", \"height\": \"1.76±0.12\", \"lw_aspect\": \"1.08±0.23\"}}\n",
    "        width_stats = {}\n",
    "        for key, stat in zip(stats.keys(), stats.values()):\n",
    "            try:\n",
    "                avg_width_meters = float(stat[\"width\"].split(\"±\")[0])\n",
    "            except Exception:\n",
    "                try:\n",
    "                    avg_width_meters = float(stat[\"width\"].split(\"+-\")[0])\n",
    "                except Exception:\n",
    "                    avg_width_meters = None\n",
    "            width_stats[key] = avg_width_meters\n",
    "        ### Applications of the functions:\n",
    "        #generate optical sensor data - applications\n",
    "        potential_annotations = pd.DataFrame()\n",
    "        opt_sensors = ['CAM_FRONT', \"CAM_BACK_RIGHT\", \"CAM_FRONT_RIGHT\", \"CAM_BACK\", \"CAM_BACK_LEFT\", \"CAM_FRONT_LEFT\" ]\n",
    "        for sensor in opt_sensors:\n",
    "            sensor_data = generate_potential_annotations(sensor)\n",
    "            if sensor_data is None:\n",
    "                print (\"scene doesn't have all the files, skipping to the next one\")\n",
    "                scenes_with_missing_files.append(sample_token)\n",
    "                next_scene = nusc.get('sample',sample_token)['next']\n",
    "                break\n",
    "            if sensor_data.shape[0] == 0:\n",
    "                print (\"No detections, skipping to next sensor\")\n",
    "                continue\n",
    "                \n",
    "            potential_annotations = pd.concat([potential_annotations, sensor_data])\n",
    "        if sensor_data is None:\n",
    "            next_scene = nusc.get('sample',sample_token)['next']\n",
    "            continue\n",
    "        if potential_annotations.shape[0] > 0:\n",
    "            potential_annotations[['lidar_x', 'lidar_y', 'lidar_z']] = potential_annotations.apply(\n",
    "                lambda row: pd.Series(convert_cam_to_lidar(my_sample, row['sensor_channel'], np.array([row['camera_point_x'], row['camera_point_y'], row['camera_point_z'], 1]))),\n",
    "                axis=1\n",
    "            )\n",
    "            # Example usage with your DataFrame:\n",
    "            potential_annotations['polar_coordinates'] = potential_annotations.apply(\n",
    "                lambda row: cartesian_to_polar(row['camera_point_x'], row['camera_point_y'], row['camera_point_z']),\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            next_scene = nusc.get('sample',sample_token)['next']\n",
    "            continue\n",
    "\n",
    "        #read lidar data and process it\n",
    "        sensor = 'LIDAR_TOP'\n",
    "        lidar_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "        # Get the image file path\n",
    "        lidar_filepath = lidar_data['filename']\n",
    "        lidar_filepath = os.path.join(nusc.dataroot, lidar_filepath)\n",
    "        # nusc = NuScenes(version='v1.0-mini', dataroot='/data/sets/nuscenes', verbose=False)\n",
    "        pcd_bin_file = os.path.join(nusc.dataroot, nusc.get('sample_data', my_sample['data'][sensor])['filename'])\n",
    "        \n",
    "        pc = LidarPointCloud.from_file(pcd_bin_file)\n",
    "        bin_pcd = pc.points.T\n",
    "        bin_pcd_only_axis = bin_pcd.reshape((-1, 4))[:, 0:3]\n",
    "\n",
    "        o3d_pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(bin_pcd_only_axis))\n",
    "        bin_pcd_with_intensity = bin_pcd.reshape((-1, 4))\n",
    "        intensity_values = bin_pcd_with_intensity[:,3]\n",
    "        \n",
    "        full_lidar_df = pd.DataFrame({\n",
    "        'x': bin_pcd_only_axis[:, 0],\n",
    "        'y': bin_pcd_only_axis[:, 1],\n",
    "        'z': bin_pcd_only_axis[:, 2],\n",
    "        'intensity': intensity_values\n",
    "            })\n",
    "        \n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        dataroot = os.path.join(current_dir,\"data\",\"sets\",\"nuscenes\")\n",
    "\n",
    "        tagged_points = pd.DataFrame()\n",
    "\n",
    "         #first_sample_token = my_scene['first_sample_token']\n",
    "\n",
    "        sample = nusc.get('sample', sample_token)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ann_tokens = sample['anns']\n",
    "        if type(ann_tokens) != list:\n",
    "            ann_tokens = [ann_tokens]\n",
    "\n",
    "\n",
    "        for ann_token in ann_tokens:\n",
    "            ann = nusc.get('sample_annotation',ann_token)\n",
    "            lidar_data = sample['data']['LIDAR_TOP']\n",
    "\n",
    "            data_path,boxes,camera_intrinsic = nusc.get_sample_data(lidar_data,selected_anntokens=[ann_token], )\n",
    "            \n",
    "            lidar_rec = nusc.get('sample_data',lidar_data)\n",
    "            \n",
    "            mask = points_in_box(boxes[0],pc.points[:3])\n",
    "            object_type =pd.DataFrame({ \"key\":ann_token, 'text': [ann['category_name']] *  np.sum(mask)})\n",
    "            ann_points = pc.points[:,mask].T\n",
    "            ann_points = pd.DataFrame(pc.points[:,mask].T)\n",
    "            ann_points = pd.concat([object_type, ann_points ], axis = 1).rename(columns={\"key\":\"key\", 0: 'x', 1: 'y', 2: 'z', 3: 'intensity', 'text': 'label'})\n",
    "            tagged_points = pd.concat([ann_points, tagged_points])\n",
    "        ground_truth = tagged_points\n",
    "\n",
    "        ###create the ground truth data\n",
    "        ground_truth = ground_truth[ground_truth['label'].isin(['vehicle.car', 'vehicle.truck', 'human.pedestrian.adult'])]\n",
    "        lidar_grid = create_grid_map_lidar(full_lidar_df)\n",
    "        \n",
    "        if lidar_grid is None:\n",
    "            print (\"scene doesn't have a valid lidar input, skipping to the next scene\")\n",
    "            scenes_with_missing_files.append(sample_token)\n",
    "            next_scene = nusc.get('sample',sample_token)['next']\n",
    "            continue\n",
    "\n",
    "        #apply one hot encoding\n",
    "        encoded_columns= pd.get_dummies(potential_annotations, columns=['object'], prefix='object', drop_first=False).iloc[:,-3:]\n",
    "        potential_annotations = pd.concat([potential_annotations, encoded_columns], axis=1)\n",
    "\n",
    "        #create a grid map for the\n",
    "        objects_dict = {}\n",
    "        objects_grid_maps = []\n",
    "        possible_objects = [col for col in potential_annotations.columns if col.startswith('object_')]\n",
    "        for i in range(len(possible_objects)):\n",
    "            objects_dict[possible_objects[i].split(\"_\")[-1]] = i\n",
    "            display(\"objects dict: \", objects_dict)\n",
    "            display(\"potential_anotations: \",potential_annotations)\n",
    "            grid_map = create_grid_map(potential_annotations, object_type = possible_objects[i])\n",
    "            objects_grid_maps.append(grid_map)\n",
    "        objects_grid_maps_tensor = torch.tensor(objects_grid_maps, dtype=torch.float)\n",
    "\n",
    "        #multiply by 1000 so the input will be suitable for Llama model (receives only integers)\n",
    "        objects_grid_maps_tensor_multiplied = torch.round(objects_grid_maps_tensor * 1000).to(torch.long)\n",
    "\n",
    "        ###create a ground truth map\n",
    "        # # **Calibrate Optical points with LIDAR**\n",
    "        ###create the ground truth data\n",
    "        # Rename categories to match grid map object names\n",
    "        ground_truth['label'] = ground_truth['label'].replace({\n",
    "            'vehicle.car': 'car',\n",
    "            'vehicle.truck': 'truck',\n",
    "            'human.pedestrian.adult': 'person'\n",
    "        })\n",
    "        \n",
    "        ground_truth = ground_truth[ground_truth['label'].isin(['car', 'truck', 'person'])]\n",
    "#         display(ground_truth)\n",
    "        ###convert camera point to lidar point\n",
    "\n",
    "        # Example usage:\n",
    "        ground_truth_map, unique_labels = create_ground_truth_map(ground_truth)\n",
    "        if ground_truth_map is None:\n",
    "            print (\"ground truth is empty, skipping to the next frame\")\n",
    "            next_scene = nusc.get('sample',sample_token)['next']\n",
    "            continue\n",
    "            \n",
    "        ground_truth_tensor = torch.tensor(ground_truth_map).to(torch.float32)\n",
    "        #pad the tensor\n",
    "        padded_ground_truth_tensor = pad_tensor_to_target(ground_truth_tensor, (num_objects, x_size, y_size))\n",
    "        padded_objects_grid_maps_tensor_multiplied = pad_tensor_to_target(objects_grid_maps_tensor_multiplied, (num_objects, x_size, y_size))\n",
    "        padded_lidar_grid = pad_tensor_to_target(torch.tensor(lidar_grid).float().unsqueeze(0), (1, x_size, y_size))\n",
    "        concat_lidar_opt = torch.cat([padded_lidar_grid, padded_objects_grid_maps_tensor_multiplied], dim=0)\n",
    "        #add to the batch the data\n",
    "        display(concat_lidar_opt.unsqueeze(0).size())\n",
    "        display(training_batch.size())\n",
    "        training_batch = torch.cat((training_batch,concat_lidar_opt.unsqueeze(0)), dim=0)\n",
    "        label_batch = torch.cat((label_batch, padded_ground_truth_tensor.unsqueeze(0)), dim=0)\n",
    "        \n",
    "        #save the ego-pose and calibrated sensor data\n",
    "        lidar_sample_data_token = my_sample['data']['LIDAR_TOP']\n",
    "        lidar_sample_data = nusc.get('sample_data', lidar_sample_data_token)\n",
    "\n",
    "        # 3. Get the ego_pose and calibrated_sensor records using tokens from the lidar_sample_data\n",
    "        ego_pose_record = nusc.get('ego_pose', lidar_sample_data['ego_pose_token'])\n",
    "        calibrated_sensor_record = nusc.get('calibrated_sensor', lidar_sample_data['calibrated_sensor_token'])\n",
    "        sample_token_key = sample_token\n",
    "        logs[training_batch.size()[0] -1] = [sample_token_key, ego_pose_record, calibrated_sensor_record]\n",
    "        print (\"next_scene is: \",next_scene)\n",
    "        print (\"---------\")\n",
    "        print (my_scene['last_sample_token'])\n",
    "        \n",
    "        # --- לוגיקת שמירת CHECKPOINT ---\n",
    "        # נשמור את המצב הנוכחי כל SAVE_EVERY_N_SAMPLES דגימות\n",
    "        # התנאי `training_batch.size(0) > 0` מוודא שלא נשמור לפני שעיבדנו משהו\n",
    "        if training_batch.size(0) > 0 and training_batch.size(0) % SAVE_EVERY_N_SAMPLES == 0:\n",
    "            print(f\"\\n💾 שומר checkpoint אחרי {training_batch.size(0)} דגימות מעובדות...\")\n",
    "            \n",
    "            # המצב שנשמור הוא המצב של *האיטרציה הבאה*\n",
    "            state_to_save = {\n",
    "                'scene_idx': scene_idx,\n",
    "                'next_scene': nusc.get('sample', sample_token)['next'],\n",
    "                'training_batch': training_batch,\n",
    "                'label_batch': label_batch,\n",
    "                'logs': logs,\n",
    "                'not_found_files': not_found_files,\n",
    "                'scenes_with_missing_files': scenes_with_missing_files,\n",
    "            }\n",
    "            torch.save(state_to_save, CHECKPOINT_PATH)\n",
    "            print(f\"השמירה הושלמה. הקובץ נשמר ב: {CHECKPOINT_PATH}\\n\")\n",
    "            print (\"=================\")\n",
    "            print (\"=================\")\n",
    "        display(next_scene)\n",
    "        if next_scene == '' and my_scene['last_sample_token']:\n",
    "            print (\"finished one session, going to the next one\")\n",
    "            next_scene = None\n",
    "            scene_idx +=1\n",
    "            pbar.update(1)  # Update progress bar when moving to next scene\n",
    "            print (fr'moving to another scene, added 1 to scene_idx now  is {scene_idx}')\n",
    "            continue\n",
    "        elif next_scene == my_scene['last_sample_token']:\n",
    "            pbar.update(1)  # Update final progress\n",
    "            scene_idx +=1\n",
    "        else:\n",
    "            next_scene = nusc.get('sample',sample_token)['next']\n",
    "        print (\"number of samples in training_batch:\", training_batch.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_optical_grid_map(grid_map):\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    data = np.array(grid_map, dtype = np.float32)\n",
    "    sns.heatmap(data, cmap='viridis', cbar_kws={'label': 'Values'})\n",
    "    plt.title('Map Heatmap')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "תיקיית העבודה הנוכחית היא: C:\\Users\\yuval\\nuscenes-devkit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# קבל את תיקיית העבודה הנוכחית\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "print(f\"תיקיית העבודה הנוכחית היא: {current_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'log_data_1_meters.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "output_filename = fr'log_data_{grid_size}_meters.json'\n",
    "\n",
    "# פתח קובץ לכתיבה ושמור את המידע בפורמט JSON\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(logs, f, indent=4)\n",
    "\n",
    "print(f\"Data has been saved to '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yrg6oYPkwjYz"
   },
   "outputs": [],
   "source": [
    "torch.save(training_batch, fr'C:\\Users\\yuval\\training_batch_{grid_size}_meter_grid.pt')\n",
    "torch.save(label_batch, fr'C:\\Users\\yuval\\label_batch_{grid_size}_meter_grid.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_token = \"ea0979999bf84ee6a6230b1bde7ec723\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ea0979999bf84ee6a6230b1bde7ec723'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mnusc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m keys\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages\\nuscenes\\nuscenes.py:216\u001b[0m, in \u001b[0;36mNuScenes.get\u001b[1;34m(self, table_name, token)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03mReturns a record from table in constant runtime.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m:param table_name: Table name.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:param token: Token of the record.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m:return: Table record. See README.md for record details for each table.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m table_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_names, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(table_name)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, table_name)[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\nuscenes_env\\lib\\site-packages\\nuscenes\\nuscenes.py:225\u001b[0m, in \u001b[0;36mNuScenes.getind\u001b[1;34m(self, table_name, token)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetind\u001b[39m(\u001b[38;5;28mself\u001b[39m, table_name: \u001b[38;5;28mstr\u001b[39m, token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    This returns the index of the record in a table in constant runtime.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    :param table_name: Table name.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    :param token: Token of the record.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    :return: The index of the record in table, table is an array.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_token2ind\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ea0979999bf84ee6a6230b1bde7ec723'"
     ]
    }
   ],
   "source": [
    "keys = nusc.get('sample', sample_token)\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_front_key = nusc.get(\"sample\", \"ecdf7078afcf4949b7310611c60a1f80\")['data']['CAM_FRONT']\n",
    "nusc.get(\"sample_data\", cam_front_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.get(\"sample_annotation\", \"bf497b43ec6e4937a9447e86035be504\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = LidarPointCloud.from_file(fr\"D:\\Nuscenes\\unified\\samples\\LIDAR_TOP\\n015-2018-11-14-18-57-54+0800__LIDAR_TOP__1542193562548545.pcd.bin\")\n",
    "bin_pcd = pc.points.T\n",
    "bin_pcd_only_axis = bin_pcd.reshape((-1, 4))[:, 0:3]\n",
    "\n",
    "o3d_pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(bin_pcd_only_axis))\n",
    "bin_pcd_with_intensity = bin_pcd.reshape((-1, 4))\n",
    "intensity_values = bin_pcd_with_intensity[:,3]\n",
    "bin_pcd_only_axis.shape\n",
    "image_fullpath = fr\"D:\\Nuscenes\\unified\\samples\\CAM_BACK_LEFT\\n015-2018-11-14-18-57-54+0800__CAM_BACK_LEFT__1542193562547423.jpg\"\n",
    "image = cv2.imread(image_fullpath)\n",
    "    \n",
    "  # Display the image\n",
    "  # cv2_imshow(image)\n",
    "################################\n",
    "# Load the model for detecting potential annotations\n",
    "\n",
    "\n",
    "# Convert the NumPy array to a PIL Image object\n",
    "image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) #added color conversion\n",
    "results = detector(image_pil)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_batch[2,1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJmXKaCswjYy"
   },
   "source": [
    "# **Save the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('label_batch_only_required_scenes_completion.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Print working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Search for the file in current directory and subdirectories\n",
    "import glob\n",
    "print(\"\\nSearching for file...\")\n",
    "matching_files = glob.glob('**/training_batch_only_required_scenes.pt', recursive=True)\n",
    "print(f\"Found matches: {matching_files}\")\n",
    "\n",
    "# Alternative search using system command\n",
    "print(\"\\nAlternative search:\")\n",
    "!find / -name \"training_batch_trainval10.pt\" -type f 2>/dev/null | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(scenes_with_missing_files), scenes_with_missing_files)\n",
    "print (not_found_files)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Sensors_Fusion_Notebook",
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [
    "Xso0niPJ6pB-",
    "LF0D-7KxwjYz"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nuscenes (YuvalZiv)",
   "language": "python",
   "name": "nuscenes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
